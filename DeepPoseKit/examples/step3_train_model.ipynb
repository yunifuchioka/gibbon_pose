{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jgraving/deepposekit/blob/master/examples/step3_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPoseKit Step 3 - Train a model\n",
    "\n",
    "This is step 3 of the example notebooks for using DeepPoseKit. This notebook shows you how to use your annotated data to train a deep learning model applying data augmentation and using callbacks for logging the training process and saving the best model during training.\n",
    "\n",
    "**NOTE**: If you run into problems, you can help us improve DeepPoseKit by [opening an issue](https://github.com/jgraving/deepposekit/issues/new) or [submitting a pull request](https://help.github.com/en/articles/creating-a-pull-request-from-a-fork)\n",
    "\n",
    "**If you're using Colab**: make sure to go to the “Runtime” dropdown menu, select “Change runtime type” and select `GPU` in the \"Hardware accelerator\" drop-down menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already installed DeepPoseKit you can run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U deepposekit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from deepposekit.io import TrainingGenerator, DataGenerator\n",
    "from deepposekit.augment import FlipAxis\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "from deepposekit.models import (StackedDenseNet,\n",
    "                                DeepLabCut,\n",
    "                                StackedHourglass,\n",
    "                                LEAP)\n",
    "from deepposekit.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from deepposekit.callbacks import Logger, ModelCheckpoint\n",
    "\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "HOME = expanduser(\"~\") if not IN_COLAB else '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to download the example data into your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/Users/jake/deepposekit-data' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jgraving/deepposekit-data {HOME + '/deepposekit-data'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few example datasets to choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jake/deepposekit-data/datasets/fly/example_annotation_set.h5',\n",
       " '/Users/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " '/Users/jake/deepposekit-data/datasets/locust/annotation_data_release.h5',\n",
       " '/Users/jake/deepposekit-data/datasets/zebra/annotation_data_release.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(HOME + '/deepposekit-data/**/**/*annotation*.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a `DataGenerator`\n",
    "This creates a `DataGenerator` for loading annotated data. You can also look at the doc string for more explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data_generator = DataGenerator(HOME + '/deepposekit-data/datasets/fly/annotation_data_release.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing the generator, e.g. `data_generator[0]` returns an image-keypoints pair, which you can then visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, keypoints = data_generator[0]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "image = image[0] if image.shape[-1] is 3 else image[0, ..., 0]\n",
    "cmap = None if image.shape[-1] is 3 else 'gray'\n",
    "plt.imshow(image, cmap=cmap, interpolation='none')\n",
    "for idx, jdx in enumerate(data_generator.graph):\n",
    "    if jdx > -1:\n",
    "        plt.plot(\n",
    "            [keypoints[0, idx, 0], keypoints[0, jdx, 0]],\n",
    "            [keypoints[0, idx, 1], keypoints[0, jdx, 1]],\n",
    "            'r-'\n",
    "        )\n",
    "plt.scatter(keypoints[0, :, 0], keypoints[0, :, 1], c=np.arange(data_generator.keypoints_shape[0]), s=50, cmap=plt.cm.hsv, zorder=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an augmentation pipeline\n",
    "DeepPoseKit works with augmenters from the [imgaug package](https://github.com/aleju/imgaug).\n",
    "This is a short example using spatial augmentations with axis flipping and affine transforms\n",
    "See https://github.com/aleju/imgaug for more documentation on augmenters.\n",
    "\n",
    "`deepposekit.augment.FlipAxis` takes the `DataGenerator` as an argument to get the keypoint swapping information defined in the annotation set. When the images are mirrored keypoints for left and right sides are swapped to avoid \"confusing\" the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = []\n",
    "\n",
    "augmenter.append(FlipAxis(data_generator, axis=0))  # flip image up-down\n",
    "augmenter.append(FlipAxis(data_generator, axis=1))  # flip image left-right \n",
    "\n",
    "sometimes = []\n",
    "sometimes.append(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "                            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                            shear=(-8, 8),\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL,\n",
    "                            mode=ia.ALL)\n",
    "                 )\n",
    "sometimes.append(iaa.Affine(scale=(0.8, 1.2),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter.append(iaa.Sometimes(0.75, sometimes))\n",
    "augmenter.append(iaa.Affine(rotate=(-180, 180),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter = iaa.Sequential(augmenter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image-keypoints pair, apply augmentation, visualize it. Rerun this cell to see multiple random augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, keypoints = data_generator[0]\n",
    "image, keypoints = augmenter(images=image, keypoints=keypoints)\n",
    "plt.figure(figsize=(5,5))\n",
    "image = image[0] if image.shape[-1] is 3 else image[0, ..., 0]\n",
    "cmap = None if image.shape[-1] is 3 else 'gray'\n",
    "plt.imshow(image, cmap=cmap, interpolation='none')\n",
    "for idx, jdx in enumerate(data_generator.graph):\n",
    "    if jdx > -1:\n",
    "        plt.plot(\n",
    "            [keypoints[0, idx, 0], keypoints[0, jdx, 0]],\n",
    "            [keypoints[0, idx, 1], keypoints[0, jdx, 1]],\n",
    "            'r-'\n",
    "        )\n",
    "plt.scatter(keypoints[0, :, 0], keypoints[0, :, 1], c=np.arange(data_generator.keypoints_shape[0]), s=50, cmap=plt.cm.hsv, zorder=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a `TrainingGenerator`\n",
    "This creates a `TrainingGenerator` from the `DataGenerator` for training the model with annotated data. The `TrainingGenerator` uses the `DataGenerator` to load image-keypoints pairs and then applies the augmentation and draws the confidence maps for training the model.\n",
    "\n",
    "If you're using `StackedDenseNet`, `StackedHourglass`, or `DeepLabCut` you should set `downsample_factor=2` for 1/4x outputs or `downsample_factor=3` for 1/8x outputs (1/8x is faster). Here it is set to `downsample_factor=3` to maximize speed. If you are using `LEAP` you should set the `downsample_factor=0` for 1x outputs.\n",
    "\n",
    "The `validation_split` argument defines how many training examples to use for validation during training. If your dataset is small (such as initial annotations for active learning), you can set this to `validation_split=0`, which will just use the training set for model fitting. However, when using callbacks, make sure to set `monitor=\"loss\"` instead of `monitor=\"val_loss\"`.\n",
    "\n",
    "Visualizing the outputs in the next section also works best with `downsample_factor=0`.\n",
    "\n",
    "You can also look at the doc string for more explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_train': 1350,\n",
       " 'n_validation': 150,\n",
       " 'validation_split': 0.1,\n",
       " 'downsample_factor': 3,\n",
       " 'output_shape': (24, 24),\n",
       " 'n_output_channels': 66,\n",
       " 'shuffle': True,\n",
       " 'sigma': 5,\n",
       " 'output_sigma': 0.625,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 1,\n",
       " 'random_seed': 1,\n",
       " 'augmenter': True,\n",
       " 'datapath': '/Users/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'generator': 'DataGenerator',\n",
       " 'n_samples': 1500,\n",
       " 'image_shape': (192, 192, 1),\n",
       " 'keypoints_shape': (32, 2)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = TrainingGenerator(generator=data_generator,\n",
    "                                    downsample_factor=3,\n",
    "                                    augmenter=augmenter,\n",
    "                                    sigma=5,\n",
    "                                    validation_split=0.1, \n",
    "                                    use_graph=True,\n",
    "                                    random_seed=1,\n",
    "                                    graph_scale=1)\n",
    "train_generator.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the `TrainingGenerator` output\n",
    "This plots the training data output from the `TrainingGenerator` to ensure that the augmentation is working and the confidence maps look good. Rerun this cell to see random augmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_keypoints = data_generator.keypoints_shape[0]\n",
    "batch = train_generator(batch_size=1, validation=False)[0]\n",
    "inputs = batch[0]\n",
    "outputs = batch[1]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\n",
    "ax1.set_title('image')\n",
    "ax1.imshow(inputs[0,...,0], cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "ax2.set_title('posture graph')\n",
    "ax2.imshow(outputs[0,...,n_keypoints:-1].max(-1))\n",
    "\n",
    "ax3.set_title('keypoints confidence')\n",
    "ax3.imshow(outputs[0,...,:n_keypoints].max(-1))\n",
    "\n",
    "ax4.set_title('posture graph and keypoints confidence')\n",
    "ax4.imshow(outputs[0,...,-1], vmin=0)\n",
    "plt.show()\n",
    "\n",
    "train_generator.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model\n",
    "Here you can define a model to train with your data. You can use our `StackedDenseNet` model, `StackedHourglass` model, `DeepLabCut` model, or the `LEAP` model. The default settings for each model should work well for most datasets, but you can customize the model architecture. The `DeepLabCut` model has multiple pretrained (on ImageNet) backbones available for using transfer learning, including the original ResNet50 (He et al. 2015)  as well as the faster MobileNetV2 (Sandler et al. 2018; see  also Mathis et al. 2019) and DenseNet121 (Huang et al. 2017). We'll select `StackedDenseNet` and set `n_stacks=2` for 2 hourglasses, with `growth_rate=32` (32 filters per convolution). Adjust the `growth_rate` and/or `n_stacks` to change model performance (and speed). You can also set `pretrained=True` to use transfer learning with `StackedDenseNet`, which uses a DenseNet121 pretrained on ImageNet to encode the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepposekit.models import DeepLabCut, StackedDenseNet, StackedHourglass, LEAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also look at the doc strings for any of the models to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackedDenseNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLabCut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StackedDenseNet(train_generator, n_stacks=2, growth_rate=32, pretrained=True)\n",
    "\n",
    "#model = DeepLabCut(train_generator, backbone=\"resnet50\")\n",
    "#model = DeepLabCut(train_generator, backbone=\"mobilenetv2\", alpha=0.35) # Increase alpha to improve accuracy\n",
    "#model = DeepLabCut(train_generator, backbone=\"densenet121\")\n",
    "\n",
    "#model = LEAP(train_generator)\n",
    "#model = StackedHourglass(train_generator)\n",
    "\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the prediction speed\n",
    "This generates a random set of input images for the model to test how fast the model can predict keypoint locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = (10000,) + data_generator.image_shape\n",
    "x = np.random.randint(0, 255, data_size, dtype=\"uint8\")\n",
    "y = model.predict(x[:100], batch_size=100) # make sure the model is in GPU memory\n",
    "t0 = time.time()\n",
    "y = model.predict(x, batch_size=100, verbose=1)\n",
    "t1 = time.time()\n",
    "print(x.shape[0] / (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks to enhance model training\n",
    "Here you can define callbacks to pass to the model for use during training. You can use any callbacks available in `deepposekit.callbacks` or `tensorflow.keras.callbacks`\n",
    "\n",
    "Remember, if you set `validation_split=0` for your `TrainingGenerator`, which will just use the training set for model fitting, make sure to set `monitor=\"loss\"` instead of `monitor=\"val_loss\"`.\n",
    "\n",
    "\n",
    "`Logger` evaluates the validation set (or training set if `validation_split=0` in the `TrainingGenerator`) at the end of each epoch and saves the evaluation data to a HDF5 log file (if `filepath` is set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(validation_batch_size=10,\n",
    "    # filepath saves the logger data to a .h5 file\n",
    "    # filepath=HOME + \"/deepposekit-data/datasets/fly/log_densenet.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReduceLROnPlateau` automatically reduces the learning rate of the optimizer when the validation loss stops improving. This helps the model to reach a better optimum at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelCheckpoint` automatically saves the model when the validation loss improves at the end of each epoch. This allows you to automatically save the best performing model during training, without having to evaluate the performance manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    HOME + \"/deepposekit-data/datasets/fly/best_model_densenet.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    # monitor=\"loss\" # use if validation_split=0\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EarlyStopping` automatically stops the training session when the validation loss stops improving for a set number of epochs, which is set with the `patience` argument. This allows you to save time when training your model if there's not more improvment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    # monitor=\"loss\" # use if validation_split=0\n",
    "    min_delta=0.001,\n",
    "    patience=100,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of callbacks to pass to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stop, reduce_lr, model_checkpoint, logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "\n",
    "This fits the model for a set number of epochs with small batches of data. If you have a small dataset initially you can set `batch_size` to a small value and manually set `steps_per_epoch` to some large value, e.g. 500, to increase the number of batches per epoch, otherwise this is automatically determined by the size of the dataset.\n",
    "\n",
    "The number of `epochs` is set to `epochs=200` for demonstration purposes. **Increase the number of epochs to train the model longer, for example `epochs=1000`**. The `EarlyStopping` callback will then automatically end training if there is no improvement. See the doc string for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/.local/lib/python3.6/site-packages/deepposekit/models/engine.py:135: UserWarning: \n",
      "Automatically compiling with default settings: model.compile('adam', 'mse')\n",
      "Call model.compile() manually to use non-default settings.\n",
      "\n",
      "  \"\"\"\\nAutomatically compiling with default settings: model.compile('adam', 'mse')\\n\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "83/84 [============================>.] - ETA: 1s - loss: 323.0233 - output_0_loss: 117.4204 - output_1_loss: 105.2768 - output_2_loss: 100.3262\n",
      "Epoch 00001: val_loss improved from inf to 649.50727, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 36.77 (0%:  0.09, 5%:  2.83, 25%: 13.01, 50%: 29.24, 75%: 54.46, 95%: 112.65, 100%: 126.22) \n",
      "confidence - mean:  0.17 (0%: -0.01, 5%: -0.00, 25%:  0.02, 50%:  0.14, 75%:  0.28, 95%:  0.62, 100%:  0.82) \n",
      "\n",
      "84/84 [==============================] - 122s 1s/step - loss: 322.0896 - output_0_loss: 117.0339 - output_1_loss: 104.9891 - output_2_loss: 100.0667 - val_loss: 649.5073 - val_output_0_loss: 207.4423 - val_output_1_loss: 209.2033 - val_output_2_loss: 232.8616\n",
      "Epoch 2/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 229.8442 - output_0_loss: 81.6332 - output_1_loss: 75.8700 - output_2_loss: 72.3410 - ETA: 12s - loss: 248.7607 - output_0_loss: 86.2175 - output_1_loss - ETA: 36s - loss: 240.8283 - output_0_loss: 84.\n",
      "Epoch 00002: val_loss improved from 649.50727 to 256.52428, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean: 15.86 (0%:  0.08, 5%:  1.12, 25%:  2.89, 50%:  5.60, 75%: 22.94, 95%: 58.04, 100%: 147.26) \n",
      "confidence - mean:  0.24 (0%:  0.02, 5%:  0.06, 25%:  0.13, 50%:  0.24, 75%:  0.33, 95%:  0.50, 100%:  0.77) \n",
      "\n",
      "84/84 [==============================] - 83s 991ms/step - loss: 229.6573 - output_0_loss: 81.5842 - output_1_loss: 75.8275 - output_2_loss: 72.2455 - val_loss: 256.5243 - val_output_0_loss: 91.5798 - val_output_1_loss: 85.5989 - val_output_2_loss: 79.3456\n",
      "Epoch 3/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 193.1603 - output_0_loss: 74.1194 - output_1_loss: 64.8914 - output_2_loss: 54.1495\n",
      "Epoch 00003: val_loss improved from 256.52428 to 187.44598, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  6.78 (0%:  0.04, 5%:  0.80, 25%:  1.87, 50%:  3.10, 75%:  5.16, 95%: 29.90, 100%: 146.74) \n",
      "confidence - mean:  0.41 (0%:  0.06, 5%:  0.20, 25%:  0.30, 50%:  0.41, 75%:  0.50, 95%:  0.64, 100%:  0.89) \n",
      "\n",
      "84/84 [==============================] - 71s 844ms/step - loss: 193.0296 - output_0_loss: 74.0942 - output_1_loss: 64.8366 - output_2_loss: 54.0987 - val_loss: 187.4460 - val_output_0_loss: 74.6579 - val_output_1_loss: 62.3527 - val_output_2_loss: 50.4354\n",
      "Epoch 4/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 160.0097 - output_0_loss: 67.4516 - output_1_loss: 50.6212 - output_2_loss: 41.9369\n",
      "Epoch 00004: val_loss improved from 187.44598 to 161.71868, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  4.76 (0%:  0.08, 5%:  0.74, 25%:  1.71, 50%:  2.65, 75%:  4.27, 95%: 15.61, 100%: 114.29) \n",
      "confidence - mean:  0.49 (0%:  0.04, 5%:  0.24, 25%:  0.39, 50%:  0.49, 75%:  0.60, 95%:  0.77, 100%:  0.94) \n",
      "\n",
      "84/84 [==============================] - 68s 810ms/step - loss: 159.8348 - output_0_loss: 67.4113 - output_1_loss: 50.5448 - output_2_loss: 41.8786 - val_loss: 161.7187 - val_output_0_loss: 68.0756 - val_output_1_loss: 50.2979 - val_output_2_loss: 43.3452\n",
      "Epoch 5/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 139.2533 - output_0_loss: 62.5759 - output_1_loss: 41.2882 - output_2_loss: 35.3892\n",
      "Epoch 00005: val_loss improved from 161.71868 to 134.60147, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.80 (0%:  0.00, 5%:  0.58, 25%:  1.48, 50%:  2.39, 75%:  3.76, 95%: 10.36, 100%: 87.59) \n",
      "confidence - mean:  0.58 (0%:  0.03, 5%:  0.25, 25%:  0.48, 50%:  0.59, 75%:  0.70, 95%:  0.83, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 73s 865ms/step - loss: 139.1379 - output_0_loss: 62.5397 - output_1_loss: 41.2379 - output_2_loss: 35.3602 - val_loss: 134.6015 - val_output_0_loss: 60.8337 - val_output_1_loss: 39.5042 - val_output_2_loss: 34.2636\n",
      "Epoch 6/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 126.9258 - output_0_loss: 58.8887 - output_1_loss: 36.3729 - output_2_loss: 31.6642 - ETA: 13s \n",
      "Epoch 00006: val_loss improved from 134.60147 to 120.62412, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.32 (0%:  0.03, 5%:  0.59, 25%:  1.41, 50%:  2.19, 75%:  3.41, 95%:  8.64, 100%: 112.91) \n",
      "confidence - mean:  0.61 (0%:  0.03, 5%:  0.28, 25%:  0.51, 50%:  0.62, 75%:  0.74, 95%:  0.88, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 74s 878ms/step - loss: 126.9042 - output_0_loss: 58.8731 - output_1_loss: 36.3639 - output_2_loss: 31.6672 - val_loss: 120.6241 - val_output_0_loss: 57.0939 - val_output_1_loss: 33.9616 - val_output_2_loss: 29.5686\n",
      "Epoch 7/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 116.5392 - output_0_loss: 55.1216 - output_1_loss: 32.4400 - output_2_loss: 28.9776\n",
      "Epoch 00007: val_loss improved from 120.62412 to 116.09488, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.30 (0%:  0.00, 5%:  0.61, 25%:  1.36, 50%:  2.01, 75%:  3.05, 95%:  8.64, 100%: 117.26) \n",
      "confidence - mean:  0.63 (0%:  0.02, 5%:  0.26, 25%:  0.52, 50%:  0.65, 75%:  0.76, 95%:  0.90, 100%:  1.14) \n",
      "\n",
      "84/84 [==============================] - 72s 853ms/step - loss: 116.5509 - output_0_loss: 55.1121 - output_1_loss: 32.4443 - output_2_loss: 28.9945 - val_loss: 116.0949 - val_output_0_loss: 54.7085 - val_output_1_loss: 32.4040 - val_output_2_loss: 28.9824\n",
      "Epoch 8/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 107.7918 - output_0_loss: 50.6537 - output_1_loss: 29.7803 - output_2_loss: 27.3578 - ETA: 33s - loss: 109.4795 - output_0_los\n",
      "Epoch 00008: val_loss improved from 116.09488 to 104.92290, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.04 (0%:  0.00, 5%:  0.61, 25%:  1.34, 50%:  2.01, 75%:  3.08, 95%:  8.07, 100%: 91.10) \n",
      "confidence - mean:  0.65 (0%:  0.03, 5%:  0.35, 25%:  0.55, 50%:  0.67, 75%:  0.76, 95%:  0.87, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 74s 884ms/step - loss: 107.6679 - output_0_loss: 50.6027 - output_1_loss: 29.7395 - output_2_loss: 27.3257 - val_loss: 104.9229 - val_output_0_loss: 49.8455 - val_output_1_loss: 28.5849 - val_output_2_loss: 26.4924\n",
      "Epoch 9/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 100.4165 - output_0_loss: 46.7889 - output_1_loss: 27.7644 - output_2_loss: 25.8633\n",
      "Epoch 00009: val_loss improved from 104.92290 to 93.12043, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.94 (0%:  0.00, 5%:  0.45, 25%:  1.09, 50%:  1.79, 75%:  2.83, 95%:  7.79, 100%: 82.12) \n",
      "confidence - mean:  0.66 (0%:  0.01, 5%:  0.35, 25%:  0.58, 50%:  0.69, 75%:  0.78, 95%:  0.89, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 74s 876ms/step - loss: 100.7263 - output_0_loss: 46.8733 - output_1_loss: 27.8763 - output_2_loss: 25.9767 - val_loss: 93.1204 - val_output_0_loss: 44.7253 - val_output_1_loss: 25.2101 - val_output_2_loss: 23.1851\n",
      "Epoch 10/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 96.1305 - output_0_loss: 44.3607 - output_1_loss: 26.6641 - output_2_loss: 25.1057  ETA: 30s - loss: 95.732\n",
      "Epoch 00010: val_loss improved from 93.12043 to 92.11134, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.92 (0%:  0.00, 5%:  0.62, 25%:  1.38, 50%:  2.00, 75%:  2.89, 95%:  7.08, 100%: 63.33) \n",
      "confidence - mean:  0.68 (0%:  0.02, 5%:  0.37, 25%:  0.59, 50%:  0.71, 75%:  0.80, 95%:  0.92, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 72s 859ms/step - loss: 96.0264 - output_0_loss: 44.3120 - output_1_loss: 26.6344 - output_2_loss: 25.0799 - val_loss: 92.1113 - val_output_0_loss: 42.9224 - val_output_1_loss: 25.2845 - val_output_2_loss: 23.9044\n",
      "Epoch 11/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 92.5523 - output_0_loss: 42.0758 - output_1_loss: 25.9035 - output_2_loss: 24.5730  ETA: 36\n",
      "Epoch 00011: val_loss improved from 92.11134 to 84.34376, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.76 (0%:  0.00, 5%:  0.54, 25%:  1.19, 50%:  1.78, 75%:  2.67, 95%:  7.16, 100%: 64.29) \n",
      "confidence - mean:  0.69 (0%:  0.02, 5%:  0.39, 25%:  0.60, 50%:  0.72, 75%:  0.81, 95%:  0.92, 100%:  1.12) \n",
      "\n",
      "84/84 [==============================] - 74s 875ms/step - loss: 92.5131 - output_0_loss: 42.0594 - output_1_loss: 25.8910 - output_2_loss: 24.5627 - val_loss: 84.3438 - val_output_0_loss: 39.1868 - val_output_1_loss: 23.0597 - val_output_2_loss: 22.0972\n",
      "Epoch 12/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 87.4257 - output_0_loss: 39.0465 - output_1_loss: 24.7557 - output_2_loss: 23.6235\n",
      "Epoch 00012: val_loss improved from 84.34376 to 77.94111, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.61 (0%:  0.00, 5%:  0.52, 25%:  1.16, 50%:  1.71, 75%:  2.58, 95%:  6.35, 100%: 64.11) \n",
      "confidence - mean:  0.68 (0%:  0.03, 5%:  0.40, 25%:  0.60, 50%:  0.70, 75%:  0.79, 95%:  0.89, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 855ms/step - loss: 87.5775 - output_0_loss: 39.0876 - output_1_loss: 24.8101 - output_2_loss: 23.6798 - val_loss: 77.9411 - val_output_0_loss: 35.5547 - val_output_1_loss: 21.9272 - val_output_2_loss: 20.4592\n",
      "Epoch 13/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 85.1518 - output_0_loss: 37.0149 - output_1_loss: 24.5914 - output_2_loss: 23.5455  ETA: 35s - loss: 86\n",
      "Epoch 00013: val_loss did not improve from 77.94111\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.75 (0%:  0.00, 5%:  0.48, 25%:  1.16, 50%:  1.82, 75%:  2.76, 95%:  6.70, 100%: 145.98) \n",
      "confidence - mean:  0.63 (0%:  0.02, 5%:  0.29, 25%:  0.54, 50%:  0.66, 75%:  0.75, 95%:  0.87, 100%:  1.12) \n",
      "\n",
      "84/84 [==============================] - 73s 870ms/step - loss: 85.2755 - output_0_loss: 37.0573 - output_1_loss: 24.6323 - output_2_loss: 23.5858 - val_loss: 91.2939 - val_output_0_loss: 39.6242 - val_output_1_loss: 26.4572 - val_output_2_loss: 25.2126\n",
      "Epoch 14/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 81.0037 - output_0_loss: 34.6089 - output_1_loss: 23.6669 - output_2_loss: 22.7279\n",
      "Epoch 00014: val_loss improved from 77.94111 to 71.28131, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.47 (0%:  0.00, 5%:  0.48, 25%:  1.11, 50%:  1.73, 75%:  2.60, 95%:  6.03, 100%: 60.17) \n",
      "confidence - mean:  0.70 (0%:  0.03, 5%:  0.43, 25%:  0.62, 50%:  0.71, 75%:  0.80, 95%:  0.92, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 76s 903ms/step - loss: 81.0792 - output_0_loss: 34.6343 - output_1_loss: 23.6933 - output_2_loss: 22.7516 - val_loss: 71.2813 - val_output_0_loss: 31.2232 - val_output_1_loss: 20.5185 - val_output_2_loss: 19.5395\n",
      "Epoch 15/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 78.8600 - output_0_loss: 33.2225 - output_1_loss: 23.2626 - output_2_loss: 22.3749\n",
      "Epoch 00015: val_loss did not improve from 71.28131\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.80 (0%:  0.04, 5%:  0.62, 25%:  1.32, 50%:  1.95, 75%:  2.79, 95%:  7.17, 100%: 69.10) \n",
      "confidence - mean:  0.69 (0%:  0.03, 5%:  0.40, 25%:  0.60, 50%:  0.71, 75%:  0.80, 95%:  0.90, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 73s 872ms/step - loss: 78.9250 - output_0_loss: 33.2317 - output_1_loss: 23.2895 - output_2_loss: 22.4039 - val_loss: 79.7329 - val_output_0_loss: 32.7649 - val_output_1_loss: 24.0219 - val_output_2_loss: 22.9461\n",
      "Epoch 16/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 76.7901 - output_0_loss: 31.6812 - output_1_loss: 22.9682 - output_2_loss: 22.1408\n",
      "Epoch 00016: val_loss improved from 71.28131 to 64.50966, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.40 (0%:  0.00, 5%:  0.45, 25%:  1.04, 50%:  1.61, 75%:  2.46, 95%:  5.99, 100%: 64.31) \n",
      "confidence - mean:  0.71 (0%:  0.03, 5%:  0.42, 25%:  0.62, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 68s 813ms/step - loss: 76.7073 - output_0_loss: 31.6523 - output_1_loss: 22.9405 - output_2_loss: 22.1145 - val_loss: 64.5097 - val_output_0_loss: 27.5148 - val_output_1_loss: 18.9688 - val_output_2_loss: 18.0261\n",
      "Epoch 17/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 73.5409 - output_0_loss: 29.7843 - output_1_loss: 22.2168 - output_2_loss: 21.5398\n",
      "Epoch 00017: val_loss did not improve from 64.50966\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.66 (0%:  0.04, 5%:  0.59, 25%:  1.26, 50%:  1.87, 75%:  2.69, 95%:  6.30, 100%: 64.02) \n",
      "confidence - mean:  0.70 (0%:  0.05, 5%:  0.43, 25%:  0.62, 50%:  0.72, 75%:  0.80, 95%:  0.89, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 70s 829ms/step - loss: 73.5490 - output_0_loss: 29.7801 - output_1_loss: 22.2226 - output_2_loss: 21.5463 - val_loss: 68.9476 - val_output_0_loss: 27.9262 - val_output_1_loss: 20.8123 - val_output_2_loss: 20.2091\n",
      "Epoch 18/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 71.9240 - output_0_loss: 28.6360 - output_1_loss: 22.0019 - output_2_loss: 21.2861\n",
      "Epoch 00018: val_loss did not improve from 64.50966\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.36 (0%:  0.00, 5%:  0.42, 25%:  1.01, 50%:  1.60, 75%:  2.46, 95%:  6.44, 100%: 70.02) \n",
      "confidence - mean:  0.68 (0%:  0.03, 5%:  0.38, 25%:  0.59, 50%:  0.69, 75%:  0.79, 95%:  0.93, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 73s 872ms/step - loss: 72.0467 - output_0_loss: 28.6674 - output_1_loss: 22.0477 - output_2_loss: 21.3315 - val_loss: 71.1111 - val_output_0_loss: 29.0856 - val_output_1_loss: 21.7082 - val_output_2_loss: 20.3174\n",
      "Epoch 19/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 70.4079 - output_0_loss: 27.6726 - output_1_loss: 21.7286 - output_2_loss: 21.0067\n",
      "Epoch 00019: val_loss improved from 64.50966 to 60.78884, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.33 (0%:  0.00, 5%:  0.47, 25%:  1.04, 50%:  1.62, 75%:  2.42, 95%:  5.73, 100%: 92.67) \n",
      "confidence - mean:  0.72 (0%:  0.06, 5%:  0.49, 25%:  0.65, 50%:  0.73, 75%:  0.81, 95%:  0.92, 100%:  1.13) \n",
      "\n",
      "84/84 [==============================] - 73s 865ms/step - loss: 70.2750 - output_0_loss: 27.6277 - output_1_loss: 21.6868 - output_2_loss: 20.9605 - val_loss: 60.7888 - val_output_0_loss: 24.4840 - val_output_1_loss: 18.4348 - val_output_2_loss: 17.8700\n",
      "Epoch 20/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 68.6881 - output_0_loss: 26.7082 - output_1_loss: 21.3049 - output_2_loss: 20.6751- ETA: 9s - loss: 68.8161 - output_0_loss: 26.7638 - output_1_loss: 21.3413 - output_2_lo\n",
      "Epoch 00020: val_loss did not improve from 60.78884\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.49 (0%:  0.00, 5%:  0.54, 25%:  1.19, 50%:  1.78, 75%:  2.55, 95%:  5.85, 100%: 92.12) \n",
      "confidence - mean:  0.71 (0%:  0.04, 5%:  0.45, 25%:  0.63, 50%:  0.73, 75%:  0.82, 95%:  0.92, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 71s 840ms/step - loss: 68.5529 - output_0_loss: 26.6601 - output_1_loss: 21.2616 - output_2_loss: 20.6311 - val_loss: 63.1671 - val_output_0_loss: 24.8429 - val_output_1_loss: 19.4863 - val_output_2_loss: 18.8378\n",
      "Epoch 21/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 69.0921 - output_0_loss: 26.5145 - output_1_loss: 21.5763 - output_2_loss: 21.0013\n",
      "Epoch 00021: val_loss improved from 60.78884 to 59.87537, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.34 (0%:  0.04, 5%:  0.45, 25%:  1.05, 50%:  1.62, 75%:  2.44, 95%:  5.65, 100%: 92.34) \n",
      "confidence - mean:  0.72 (0%:  0.03, 5%:  0.42, 25%:  0.63, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 71s 851ms/step - loss: 69.0037 - output_0_loss: 26.4870 - output_1_loss: 21.5466 - output_2_loss: 20.9701 - val_loss: 59.8754 - val_output_0_loss: 23.6485 - val_output_1_loss: 18.4304 - val_output_2_loss: 17.7965\n",
      "Epoch 22/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 66.3811 - output_0_loss: 25.4424 - output_1_loss: 20.7732 - output_2_loss: 20.1655\n",
      "Epoch 00022: val_loss did not improve from 59.87537\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.43 (0%:  0.00, 5%:  0.50, 25%:  1.12, 50%:  1.69, 75%:  2.45, 95%:  5.89, 100%: 92.95) \n",
      "confidence - mean:  0.74 (0%:  0.05, 5%:  0.47, 25%:  0.65, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 71s 845ms/step - loss: 66.4958 - output_0_loss: 25.4766 - output_1_loss: 20.8119 - output_2_loss: 20.2073 - val_loss: 60.0591 - val_output_0_loss: 23.3426 - val_output_1_loss: 18.7177 - val_output_2_loss: 17.9988\n",
      "Epoch 23/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 65.5851 - output_0_loss: 24.8378 - output_1_loss: 20.6465 - output_2_loss: 20.1009\n",
      "Epoch 00023: val_loss improved from 59.87537 to 58.77804, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.35 (0%:  0.04, 5%:  0.47, 25%:  1.04, 50%:  1.59, 75%:  2.34, 95%:  5.66, 100%: 92.42) \n",
      "confidence - mean:  0.71 (0%:  0.02, 5%:  0.46, 25%:  0.64, 50%:  0.73, 75%:  0.81, 95%:  0.90, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 75s 894ms/step - loss: 65.5951 - output_0_loss: 24.8455 - output_1_loss: 20.6480 - output_2_loss: 20.1016 - val_loss: 58.7780 - val_output_0_loss: 22.8380 - val_output_1_loss: 18.2438 - val_output_2_loss: 17.6962\n",
      "Epoch 24/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 64.5388 - output_0_loss: 24.2951 - output_1_loss: 20.4151 - output_2_loss: 19.8286\n",
      "Epoch 00024: val_loss improved from 58.77804 to 58.56262, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.40 (0%:  0.00, 5%:  0.47, 25%:  1.11, 50%:  1.69, 75%:  2.46, 95%:  5.81, 100%: 69.17) \n",
      "confidence - mean:  0.73 (0%:  0.04, 5%:  0.48, 25%:  0.64, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 72s 857ms/step - loss: 64.3562 - output_0_loss: 24.2331 - output_1_loss: 20.3540 - output_2_loss: 19.7691 - val_loss: 58.5626 - val_output_0_loss: 22.3798 - val_output_1_loss: 18.2847 - val_output_2_loss: 17.8981\n",
      "Epoch 25/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 63.5329 - output_0_loss: 23.7516 - output_1_loss: 20.1562 - output_2_loss: 19.6252\n",
      "Epoch 00025: val_loss did not improve from 58.56262\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.36 (0%:  0.00, 5%:  0.49, 25%:  1.07, 50%:  1.63, 75%:  2.41, 95%:  6.24, 100%: 65.74) \n",
      "confidence - mean:  0.71 (0%:  0.05, 5%:  0.38, 25%:  0.62, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.10) \n",
      "\n",
      "84/84 [==============================] - 73s 865ms/step - loss: 63.5055 - output_0_loss: 23.7390 - output_1_loss: 20.1501 - output_2_loss: 19.6164 - val_loss: 63.8058 - val_output_0_loss: 24.5712 - val_output_1_loss: 19.9082 - val_output_2_loss: 19.3264\n",
      "Epoch 26/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 63.1152 - output_0_loss: 23.5570 - output_1_loss: 20.0505 - output_2_loss: 19.5077\n",
      "Epoch 00026: val_loss improved from 58.56262 to 55.19801, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.22 (0%:  0.04, 5%:  0.40, 25%:  0.88, 50%:  1.40, 75%:  2.19, 95%:  5.77, 100%: 62.48) \n",
      "confidence - mean:  0.75 (0%:  0.04, 5%:  0.46, 25%:  0.65, 50%:  0.76, 75%:  0.86, 95%:  1.00, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 73s 866ms/step - loss: 63.1056 - output_0_loss: 23.5520 - output_1_loss: 20.0471 - output_2_loss: 19.5065 - val_loss: 55.1980 - val_output_0_loss: 20.6208 - val_output_1_loss: 17.4564 - val_output_2_loss: 17.1208\n",
      "Epoch 27/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 62.4922 - output_0_loss: 23.2106 - output_1_loss: 19.9172 - output_2_loss: 19.3643\n",
      "Epoch 00027: val_loss did not improve from 55.19801\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.33 (0%:  0.00, 5%:  0.49, 25%:  1.07, 50%:  1.61, 75%:  2.34, 95%:  5.78, 100%: 61.80) \n",
      "confidence - mean:  0.71 (0%:  0.04, 5%:  0.44, 25%:  0.63, 50%:  0.72, 75%:  0.81, 95%:  0.94, 100%:  1.10) \n",
      "\n",
      "84/84 [==============================] - 70s 828ms/step - loss: 62.5687 - output_0_loss: 23.2305 - output_1_loss: 19.9434 - output_2_loss: 19.3947 - val_loss: 57.7674 - val_output_0_loss: 21.8900 - val_output_1_loss: 18.1472 - val_output_2_loss: 17.7303\n",
      "Epoch 28/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 61.3392 - output_0_loss: 22.8001 - output_1_loss: 19.5086 - output_2_loss: 19.0304\n",
      "Epoch 00028: val_loss did not improve from 55.19801\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.48 (0%:  0.00, 5%:  0.51, 25%:  1.15, 50%:  1.72, 75%:  2.50, 95%:  5.82, 100%: 63.59) \n",
      "confidence - mean:  0.75 (0%:  0.06, 5%:  0.51, 25%:  0.66, 50%:  0.76, 75%:  0.85, 95%:  0.96, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 71s 842ms/step - loss: 61.2941 - output_0_loss: 22.7826 - output_1_loss: 19.4951 - output_2_loss: 19.0164 - val_loss: 57.7211 - val_output_0_loss: 21.4193 - val_output_1_loss: 18.3879 - val_output_2_loss: 17.9139\n",
      "Epoch 29/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 61.7742 - output_0_loss: 22.8248 - output_1_loss: 19.7107 - output_2_loss: 19.2386\n",
      "Epoch 00029: val_loss did not improve from 55.19801\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.45 (0%:  0.00, 5%:  0.50, 25%:  1.11, 50%:  1.69, 75%:  2.43, 95%:  5.81, 100%: 60.24) \n",
      "confidence - mean:  0.73 (0%:  0.06, 5%:  0.46, 25%:  0.65, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 77s 917ms/step - loss: 61.7429 - output_0_loss: 22.8184 - output_1_loss: 19.6988 - output_2_loss: 19.2257 - val_loss: 59.1656 - val_output_0_loss: 22.0084 - val_output_1_loss: 18.7600 - val_output_2_loss: 18.3972\n",
      "Epoch 30/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 60.1796 - output_0_loss: 22.2971 - output_1_loss: 19.1982 - output_2_loss: 18.6843\n",
      "Epoch 00030: val_loss improved from 55.19801 to 53.08534, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.21 (0%:  0.04, 5%:  0.40, 25%:  0.96, 50%:  1.50, 75%:  2.22, 95%:  5.60, 100%: 65.27) \n",
      "confidence - mean:  0.73 (0%:  0.05, 5%:  0.46, 25%:  0.64, 50%:  0.74, 75%:  0.84, 95%:  0.94, 100%:  1.16) \n",
      "\n",
      "84/84 [==============================] - 71s 840ms/step - loss: 60.2372 - output_0_loss: 22.3165 - output_1_loss: 19.2169 - output_2_loss: 18.7038 - val_loss: 53.0853 - val_output_0_loss: 20.2282 - val_output_1_loss: 16.7698 - val_output_2_loss: 16.0873\n",
      "Epoch 31/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 59.6502 - output_0_loss: 22.1253 - output_1_loss: 19.0063 - output_2_loss: 18.5186  ETA: 38s - loss: 60.8754 - output_0_loss: 22.5286 - output_1_loss: 19.4140 -  - ETA: 35s - loss\n",
      "Epoch 00031: val_loss did not improve from 53.08534\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.21 (0%:  0.00, 5%:  0.40, 25%:  0.96, 50%:  1.48, 75%:  2.17, 95%:  6.18, 100%: 59.94) \n",
      "confidence - mean:  0.72 (0%:  0.06, 5%:  0.48, 25%:  0.64, 50%:  0.73, 75%:  0.82, 95%:  0.92, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 74s 875ms/step - loss: 59.5849 - output_0_loss: 22.1041 - output_1_loss: 18.9858 - output_2_loss: 18.4950 - val_loss: 54.5627 - val_output_0_loss: 20.5624 - val_output_1_loss: 17.3656 - val_output_2_loss: 16.6348\n",
      "Epoch 32/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 59.6168 - output_0_loss: 22.0225 - output_1_loss: 19.0331 - output_2_loss: 18.5612\n",
      "Epoch 00032: val_loss improved from 53.08534 to 50.97194, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.15 (0%:  0.04, 5%:  0.43, 25%:  0.99, 50%:  1.50, 75%:  2.20, 95%:  5.38, 100%: 62.45) \n",
      "confidence - mean:  0.72 (0%:  0.07, 5%:  0.49, 25%:  0.64, 50%:  0.73, 75%:  0.82, 95%:  0.92, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 69s 827ms/step - loss: 59.4913 - output_0_loss: 21.9805 - output_1_loss: 18.9906 - output_2_loss: 18.5202 - val_loss: 50.9719 - val_output_0_loss: 19.5045 - val_output_1_loss: 16.0313 - val_output_2_loss: 15.4361\n",
      "Epoch 33/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 58.5700 - output_0_loss: 21.6692 - output_1_loss: 18.6925 - output_2_loss: 18.2083\n",
      "Epoch 00033: val_loss improved from 50.97194 to 50.78912, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.06 (0%:  0.00, 5%:  0.45, 25%:  0.97, 50%:  1.48, 75%:  2.16, 95%:  4.95, 100%: 61.18) \n",
      "confidence - mean:  0.72 (0%:  0.12, 5%:  0.50, 25%:  0.64, 50%:  0.73, 75%:  0.80, 95%:  0.90, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 70s 835ms/step - loss: 58.5348 - output_0_loss: 21.6576 - output_1_loss: 18.6802 - output_2_loss: 18.1969 - val_loss: 50.7891 - val_output_0_loss: 18.9625 - val_output_1_loss: 16.0863 - val_output_2_loss: 15.7403\n",
      "Epoch 34/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 59.7971 - output_0_loss: 22.0090 - output_1_loss: 19.1259 - output_2_loss: 18.6623\n",
      "Epoch 00034: val_loss did not improve from 50.78912\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.25 (0%:  0.00, 5%:  0.44, 25%:  1.04, 50%:  1.58, 75%:  2.26, 95%:  5.66, 100%: 62.67) \n",
      "confidence - mean:  0.72 (0%:  0.03, 5%:  0.48, 25%:  0.63, 50%:  0.73, 75%:  0.82, 95%:  0.92, 100%:  1.12) \n",
      "\n",
      "84/84 [==============================] - 73s 864ms/step - loss: 59.9574 - output_0_loss: 22.0622 - output_1_loss: 19.1764 - output_2_loss: 18.7188 - val_loss: 54.2791 - val_output_0_loss: 20.1800 - val_output_1_loss: 17.2516 - val_output_2_loss: 16.8475\n",
      "Epoch 35/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 58.4771 - output_0_loss: 21.5477 - output_1_loss: 18.6900 - output_2_loss: 18.2394\n",
      "Epoch 00035: val_loss did not improve from 50.78912\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.20 (0%:  0.00, 5%:  0.44, 25%:  1.03, 50%:  1.54, 75%:  2.26, 95%:  5.73, 100%: 58.19) \n",
      "confidence - mean:  0.74 (0%:  0.09, 5%:  0.50, 25%:  0.65, 50%:  0.75, 75%:  0.83, 95%:  0.94, 100%:  1.12) \n",
      "\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 58.5993 - output_0_loss: 21.5903 - output_1_loss: 18.7300 - output_2_loss: 18.2791 - val_loss: 53.9135 - val_output_0_loss: 20.3145 - val_output_1_loss: 17.0830 - val_output_2_loss: 16.5160\n",
      "Epoch 36/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 58.3880 - output_0_loss: 21.5487 - output_1_loss: 18.6565 - output_2_loss: 18.1827\n",
      "Epoch 00036: val_loss did not improve from 50.78912\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.15 (0%:  0.02, 5%:  0.43, 25%:  1.00, 50%:  1.53, 75%:  2.25, 95%:  5.24, 100%: 55.26) \n",
      "confidence - mean:  0.71 (0%:  0.07, 5%:  0.47, 25%:  0.63, 50%:  0.73, 75%:  0.82, 95%:  0.92, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 75s 891ms/step - loss: 58.5077 - output_0_loss: 21.5875 - output_1_loss: 18.6963 - output_2_loss: 18.2239 - val_loss: 52.8807 - val_output_0_loss: 19.9030 - val_output_1_loss: 16.8254 - val_output_2_loss: 16.1524\n",
      "Epoch 37/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 57.9256 - output_0_loss: 21.3577 - output_1_loss: 18.5037 - output_2_loss: 18.0642\n",
      "Epoch 00037: val_loss did not improve from 50.78912\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.26 (0%:  0.00, 5%:  0.38, 25%:  0.92, 50%:  1.45, 75%:  2.19, 95%:  5.85, 100%: 92.28) \n",
      "confidence - mean:  0.73 (0%:  0.03, 5%:  0.48, 25%:  0.66, 50%:  0.74, 75%:  0.83, 95%:  0.94, 100%:  1.12) \n",
      "\n",
      "84/84 [==============================] - 71s 850ms/step - loss: 58.0239 - output_0_loss: 21.3902 - output_1_loss: 18.5381 - output_2_loss: 18.0957 - val_loss: 53.1315 - val_output_0_loss: 19.8367 - val_output_1_loss: 16.8863 - val_output_2_loss: 16.4085\n",
      "Epoch 38/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 58.5210 - output_0_loss: 21.5379 - output_1_loss: 18.7064 - output_2_loss: 18.2767\n",
      "Epoch 00038: val_loss did not improve from 50.78912\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.35 (0%:  0.05, 5%:  0.49, 25%:  1.13, 50%:  1.68, 75%:  2.41, 95%:  5.36, 100%: 68.45) \n",
      "confidence - mean:  0.75 (0%:  0.05, 5%:  0.52, 25%:  0.67, 50%:  0.76, 75%:  0.84, 95%:  0.94, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 70s 831ms/step - loss: 58.5200 - output_0_loss: 21.5328 - output_1_loss: 18.7074 - output_2_loss: 18.2798 - val_loss: 54.1525 - val_output_0_loss: 20.1913 - val_output_1_loss: 17.1624 - val_output_2_loss: 16.7987\n",
      "Epoch 39/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 56.8277 - output_0_loss: 20.9835 - output_1_loss: 18.1397 - output_2_loss: 17.7045\n",
      "Epoch 00039: val_loss improved from 50.78912 to 48.85363, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.02 (0%:  0.00, 5%:  0.37, 25%:  0.90, 50%:  1.38, 75%:  2.04, 95%:  5.20, 100%: 64.74) \n",
      "confidence - mean:  0.74 (0%:  0.04, 5%:  0.49, 25%:  0.66, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 74s 884ms/step - loss: 56.8210 - output_0_loss: 20.9791 - output_1_loss: 18.1374 - output_2_loss: 17.7045 - val_loss: 48.8536 - val_output_0_loss: 18.3685 - val_output_1_loss: 15.4235 - val_output_2_loss: 15.0616\n",
      "Epoch 40/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 56.9572 - output_0_loss: 20.9477 - output_1_loss: 18.2047 - output_2_loss: 17.8049\n",
      "Epoch 00040: val_loss improved from 48.85363 to 48.57732, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.09 (0%:  0.03, 5%:  0.40, 25%:  0.93, 50%:  1.42, 75%:  2.11, 95%:  5.55, 100%: 60.39) \n",
      "confidence - mean:  0.73 (0%:  0.06, 5%:  0.50, 25%:  0.65, 50%:  0.74, 75%:  0.83, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 75s 890ms/step - loss: 57.1637 - output_0_loss: 21.0248 - output_1_loss: 18.2695 - output_2_loss: 17.8694 - val_loss: 48.5773 - val_output_0_loss: 18.1804 - val_output_1_loss: 15.3687 - val_output_2_loss: 15.0282\n",
      "Epoch 41/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 56.6573 - output_0_loss: 20.8599 - output_1_loss: 18.1025 - output_2_loss: 17.6949\n",
      "Epoch 00041: val_loss did not improve from 48.57732\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.21 (0%:  0.00, 5%:  0.48, 25%:  1.05, 50%:  1.58, 75%:  2.24, 95%:  5.51, 100%: 68.36) \n",
      "confidence - mean:  0.72 (0%:  0.03, 5%:  0.50, 25%:  0.64, 50%:  0.73, 75%:  0.81, 95%:  0.91, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 843ms/step - loss: 56.7181 - output_0_loss: 20.8796 - output_1_loss: 18.1225 - output_2_loss: 17.7160 - val_loss: 50.8007 - val_output_0_loss: 19.0652 - val_output_1_loss: 16.1314 - val_output_2_loss: 15.6041\n",
      "Epoch 42/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 56.9398 - output_0_loss: 20.8973 - output_1_loss: 18.2252 - output_2_loss: 17.8174\n",
      "Epoch 00042: val_loss improved from 48.57732 to 45.75371, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.98 (0%:  0.00, 5%:  0.33, 25%:  0.82, 50%:  1.29, 75%:  1.96, 95%:  5.02, 100%: 63.87) \n",
      "confidence - mean:  0.74 (0%:  0.07, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.85, 95%:  0.95, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 74s 882ms/step - loss: 56.8968 - output_0_loss: 20.8845 - output_1_loss: 18.2092 - output_2_loss: 17.8031 - val_loss: 45.7537 - val_output_0_loss: 17.4098 - val_output_1_loss: 14.4365 - val_output_2_loss: 13.9074\n",
      "Epoch 43/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 56.7815 - output_0_loss: 20.8172 - output_1_loss: 18.1871 - output_2_loss: 17.7773\n",
      "Epoch 00043: val_loss did not improve from 45.75371\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.23 (0%:  0.04, 5%:  0.49, 25%:  1.07, 50%:  1.60, 75%:  2.31, 95%:  5.42, 100%: 61.81) \n",
      "confidence - mean:  0.74 (0%:  0.04, 5%:  0.50, 25%:  0.65, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 68s 806ms/step - loss: 56.6873 - output_0_loss: 20.7905 - output_1_loss: 18.1537 - output_2_loss: 17.7431 - val_loss: 51.8629 - val_output_0_loss: 19.1984 - val_output_1_loss: 16.5824 - val_output_2_loss: 16.0821\n",
      "Epoch 44/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 55.4298 - output_0_loss: 20.1382 - output_1_loss: 17.8437 - output_2_loss: 17.4479  ETA: 34s \n",
      "Epoch 00044: val_loss did not improve from 45.75371\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.30 (0%:  0.00, 5%:  0.54, 25%:  1.14, 50%:  1.68, 75%:  2.37, 95%:  5.35, 100%: 92.54) \n",
      "confidence - mean:  0.73 (0%:  0.09, 5%:  0.49, 25%:  0.65, 50%:  0.74, 75%:  0.83, 95%:  0.92, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 72s 852ms/step - loss: 55.4672 - output_0_loss: 20.1489 - output_1_loss: 17.8579 - output_2_loss: 17.4604 - val_loss: 52.1623 - val_output_0_loss: 18.9812 - val_output_1_loss: 16.7611 - val_output_2_loss: 16.4199\n",
      "Epoch 45/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 54.6538 - output_0_loss: 19.5123 - output_1_loss: 17.7671 - output_2_loss: 17.3743\n",
      "Epoch 00045: val_loss did not improve from 45.75371\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.23 (0%:  0.00, 5%:  0.45, 25%:  0.99, 50%:  1.49, 75%:  2.24, 95%:  5.59, 100%: 62.55) \n",
      "confidence - mean:  0.73 (0%:  0.03, 5%:  0.50, 25%:  0.65, 50%:  0.74, 75%:  0.83, 95%:  0.92, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 860ms/step - loss: 54.6528 - output_0_loss: 19.5078 - output_1_loss: 17.7688 - output_2_loss: 17.3761 - val_loss: 49.8268 - val_output_0_loss: 17.8945 - val_output_1_loss: 16.1665 - val_output_2_loss: 15.7658\n",
      "Epoch 46/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 54.6172 - output_0_loss: 19.3414 - output_1_loss: 17.8496 - output_2_loss: 17.4262\n",
      "Epoch 00046: val_loss did not improve from 45.75371\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.28 (0%:  0.04, 5%:  0.45, 25%:  1.02, 50%:  1.57, 75%:  2.27, 95%:  5.56, 100%: 62.93) \n",
      "confidence - mean:  0.73 (0%:  0.08, 5%:  0.49, 25%:  0.65, 50%:  0.73, 75%:  0.83, 95%:  0.93, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 69s 822ms/step - loss: 54.5560 - output_0_loss: 19.3156 - output_1_loss: 17.8312 - output_2_loss: 17.4093 - val_loss: 50.2345 - val_output_0_loss: 17.9649 - val_output_1_loss: 16.3594 - val_output_2_loss: 15.9102\n",
      "Epoch 47/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 56.0996 - output_0_loss: 19.7402 - output_1_loss: 18.3846 - output_2_loss: 17.9749\n",
      "Epoch 00047: val_loss did not improve from 45.75371\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.17 (0%:  0.04, 5%:  0.45, 25%:  1.07, 50%:  1.60, 75%:  2.29, 95%:  5.14, 100%: 74.32) \n",
      "confidence - mean:  0.75 (0%:  0.07, 5%:  0.51, 25%:  0.66, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 66s 789ms/step - loss: 55.9561 - output_0_loss: 19.6894 - output_1_loss: 18.3371 - output_2_loss: 17.9297 - val_loss: 49.3073 - val_output_0_loss: 17.3916 - val_output_1_loss: 16.1042 - val_output_2_loss: 15.8116\n",
      "Epoch 48/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 54.8960 - output_0_loss: 19.2492 - output_1_loss: 18.0032 - output_2_loss: 17.6435  ETA: 21s - loss: 55.6117 - output_0_loss: 19.4899 - o\n",
      "Epoch 00048: val_loss improved from 45.75371 to 45.37515, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.05 (0%:  0.05, 5%:  0.43, 25%:  0.98, 50%:  1.49, 75%:  2.16, 95%:  4.94, 100%: 62.46) \n",
      "confidence - mean:  0.74 (0%:  0.04, 5%:  0.50, 25%:  0.65, 50%:  0.74, 75%:  0.84, 95%:  0.94, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 72s 856ms/step - loss: 54.9989 - output_0_loss: 19.2851 - output_1_loss: 18.0364 - output_2_loss: 17.6773 - val_loss: 45.3752 - val_output_0_loss: 16.0607 - val_output_1_loss: 14.7890 - val_output_2_loss: 14.5254\n",
      "Epoch 49/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 54.3425 - output_0_loss: 19.1364 - output_1_loss: 17.8024 - output_2_loss: 17.4038\n",
      "Epoch 00049: val_loss did not improve from 45.37515\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.22 (0%:  0.04, 5%:  0.43, 25%:  0.95, 50%:  1.46, 75%:  2.13, 95%:  5.56, 100%: 150.89) \n",
      "confidence - mean:  0.74 (0%:  0.03, 5%:  0.50, 25%:  0.65, 50%:  0.75, 75%:  0.83, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 80s 954ms/step - loss: 54.3475 - output_0_loss: 19.1359 - output_1_loss: 17.8046 - output_2_loss: 17.4070 - val_loss: 48.6562 - val_output_0_loss: 17.1705 - val_output_1_loss: 15.9328 - val_output_2_loss: 15.5529\n",
      "Epoch 50/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 53.3738 - output_0_loss: 18.7177 - output_1_loss: 17.5069 - output_2_loss: 17.1492  ETA: 12s - loss: 53.2070 - output_0_loss: 18.6449 - output_1_loss: 17.4618 - output_2_loss: 17.10 - ETA: 12s - loss: 53.2127 - output_0_loss: 18.6438 - output_1_loss: 17.4658 - ou\n",
      "Epoch 00050: val_loss improved from 45.37515 to 45.27150, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.04 (0%:  0.00, 5%:  0.33, 25%:  0.80, 50%:  1.26, 75%:  2.00, 95%:  5.00, 100%: 83.38) \n",
      "confidence - mean:  0.75 (0%:  0.08, 5%:  0.49, 25%:  0.66, 50%:  0.76, 75%:  0.86, 95%:  0.96, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 71s 850ms/step - loss: 53.3765 - output_0_loss: 18.7215 - output_1_loss: 17.5070 - output_2_loss: 17.1480 - val_loss: 45.2715 - val_output_0_loss: 16.1896 - val_output_1_loss: 14.6508 - val_output_2_loss: 14.4310\n",
      "Epoch 51/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 53.1201 - output_0_loss: 18.6625 - output_1_loss: 17.4343 - output_2_loss: 17.0233\n",
      "Epoch 00051: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.06 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.39, 75%:  2.06, 95%:  5.13, 100%: 79.36) \n",
      "confidence - mean:  0.72 (0%:  0.06, 5%:  0.49, 25%:  0.64, 50%:  0.74, 75%:  0.83, 95%:  0.92, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 77s 911ms/step - loss: 52.9957 - output_0_loss: 18.6147 - output_1_loss: 17.3958 - output_2_loss: 16.9852 - val_loss: 46.3461 - val_output_0_loss: 16.1036 - val_output_1_loss: 15.2548 - val_output_2_loss: 14.9877\n",
      "Epoch 52/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 53.2571 - output_0_loss: 18.6952 - output_1_loss: 17.4799 - output_2_loss: 17.0820- ETA: 6s - loss: 53.3939 - output_0_loss: 18.7517 - output_1_loss: 17.5220 - output_2_loss:\n",
      "Epoch 00052: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.19 (0%:  0.04, 5%:  0.50, 25%:  1.05, 50%:  1.60, 75%:  2.30, 95%:  5.27, 100%: 52.25) \n",
      "confidence - mean:  0.74 (0%:  0.06, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 74s 885ms/step - loss: 53.3633 - output_0_loss: 18.7338 - output_1_loss: 17.5149 - output_2_loss: 17.1147 - val_loss: 48.0074 - val_output_0_loss: 16.8554 - val_output_1_loss: 15.7465 - val_output_2_loss: 15.4054\n",
      "Epoch 53/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.3114 - output_0_loss: 18.3068 - output_1_loss: 17.1779 - output_2_loss: 16.8267  ETA: 15s - loss: 52.9453 - output_0_loss: 18.5040 - output_1_loss: 17.3\n",
      "Epoch 00053: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.49 (0%:  0.03, 5%:  0.62, 25%:  1.31, 50%:  1.92, 75%:  2.63, 95%:  5.67, 100%: 64.62) \n",
      "confidence - mean:  0.74 (0%:  0.12, 5%:  0.52, 25%:  0.67, 50%:  0.76, 75%:  0.84, 95%:  0.92, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 73s 872ms/step - loss: 52.2699 - output_0_loss: 18.2976 - output_1_loss: 17.1636 - output_2_loss: 16.8086 - val_loss: 54.9978 - val_output_0_loss: 18.9606 - val_output_1_loss: 18.1516 - val_output_2_loss: 17.8857\n",
      "Epoch 54/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.6867 - output_0_loss: 18.4275 - output_1_loss: 17.3107 - output_2_loss: 16.9485\n",
      "Epoch 00054: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.14 (0%:  0.00, 5%:  0.43, 25%:  1.01, 50%:  1.53, 75%:  2.24, 95%:  5.20, 100%: 50.57) \n",
      "confidence - mean:  0.75 (0%:  0.10, 5%:  0.52, 25%:  0.67, 50%:  0.76, 75%:  0.84, 95%:  0.93, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 72s 857ms/step - loss: 52.6361 - output_0_loss: 18.4104 - output_1_loss: 17.2939 - output_2_loss: 16.9319 - val_loss: 47.0497 - val_output_0_loss: 16.3860 - val_output_1_loss: 15.5390 - val_output_2_loss: 15.1247\n",
      "Epoch 55/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 51.6760 - output_0_loss: 18.0786 - output_1_loss: 16.9906 - output_2_loss: 16.6067\n",
      "Epoch 00055: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.20 (0%:  0.00, 5%:  0.47, 25%:  1.04, 50%:  1.56, 75%:  2.20, 95%:  5.64, 100%: 63.27) \n",
      "confidence - mean:  0.75 (0%:  0.10, 5%:  0.53, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 71s 849ms/step - loss: 51.7137 - output_0_loss: 18.0915 - output_1_loss: 17.0040 - output_2_loss: 16.6182 - val_loss: 46.5995 - val_output_0_loss: 16.4331 - val_output_1_loss: 15.3133 - val_output_2_loss: 14.8531\n",
      "Epoch 56/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.8028 - output_0_loss: 18.4607 - output_1_loss: 17.3536 - output_2_loss: 16.9884\n",
      "Epoch 00056: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.37 (0%:  0.00, 5%:  0.57, 25%:  1.23, 50%:  1.79, 75%:  2.52, 95%:  5.36, 100%: 53.04) \n",
      "confidence - mean:  0.72 (0%:  0.11, 5%:  0.49, 25%:  0.64, 50%:  0.73, 75%:  0.83, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 74s 878ms/step - loss: 52.8130 - output_0_loss: 18.4605 - output_1_loss: 17.3572 - output_2_loss: 16.9953 - val_loss: 54.1749 - val_output_0_loss: 18.9197 - val_output_1_loss: 17.8364 - val_output_2_loss: 17.4188\n",
      "Epoch 57/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 51.4630 - output_0_loss: 17.9878 - output_1_loss: 16.9049 - output_2_loss: 16.5703  ETA: 14s - loss: 52.0633 - output_0_loss: 18.1800 - output_1_loss: 17.11\n",
      "Epoch 00057: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.23 (0%:  0.04, 5%:  0.44, 25%:  1.00, 50%:  1.53, 75%:  2.22, 95%:  5.46, 100%: 61.48) \n",
      "confidence - mean:  0.74 (0%:  0.11, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 69s 816ms/step - loss: 51.4076 - output_0_loss: 17.9667 - output_1_loss: 16.8873 - output_2_loss: 16.5536 - val_loss: 48.8468 - val_output_0_loss: 16.9419 - val_output_1_loss: 16.0769 - val_output_2_loss: 15.8281\n",
      "Epoch 58/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.2308 - output_0_loss: 18.2857 - output_1_loss: 17.1445 - output_2_loss: 16.8007\n",
      "Epoch 00058: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.03 (0%:  0.00, 5%:  0.40, 25%:  0.96, 50%:  1.47, 75%:  2.17, 95%:  4.90, 100%: 47.07) \n",
      "confidence - mean:  0.72 (0%:  0.13, 5%:  0.49, 25%:  0.64, 50%:  0.73, 75%:  0.81, 95%:  0.90, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 870ms/step - loss: 52.2624 - output_0_loss: 18.2998 - output_1_loss: 17.1529 - output_2_loss: 16.8097 - val_loss: 47.1342 - val_output_0_loss: 16.5949 - val_output_1_loss: 15.4318 - val_output_2_loss: 15.1074\n",
      "Epoch 59/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 51.8404 - output_0_loss: 18.1246 - output_1_loss: 17.0440 - output_2_loss: 16.6719\n",
      "Epoch 00059: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.29 (0%:  0.04, 5%:  0.50, 25%:  1.10, 50%:  1.62, 75%:  2.28, 95%:  5.50, 100%: 83.53) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.50, 25%:  0.68, 50%:  0.77, 75%:  0.87, 95%:  0.98, 100%:  1.13) \n",
      "\n",
      "84/84 [==============================] - 69s 826ms/step - loss: 51.9515 - output_0_loss: 18.1676 - output_1_loss: 17.0806 - output_2_loss: 16.7033 - val_loss: 51.4973 - val_output_0_loss: 17.7404 - val_output_1_loss: 16.9291 - val_output_2_loss: 16.8278\n",
      "Epoch 60/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.0442 - output_0_loss: 18.1367 - output_1_loss: 17.1198 - output_2_loss: 16.7877\n",
      "Epoch 00060: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.08 (0%:  0.04, 5%:  0.46, 25%:  0.99, 50%:  1.52, 75%:  2.13, 95%:  5.10, 100%: 76.99) \n",
      "confidence - mean:  0.73 (0%:  0.11, 5%:  0.51, 25%:  0.65, 50%:  0.75, 75%:  0.84, 95%:  0.92, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 72s 854ms/step - loss: 52.0460 - output_0_loss: 18.1381 - output_1_loss: 17.1208 - output_2_loss: 16.7871 - val_loss: 46.7216 - val_output_0_loss: 16.5436 - val_output_1_loss: 15.2770 - val_output_2_loss: 14.9009\n",
      "Epoch 61/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.5843 - output_0_loss: 18.3689 - output_1_loss: 17.2831 - output_2_loss: 16.9322  ETA: 21s - loss: 52.8627 - output_0_loss: 18.4471 - output_1_loss: 17.3811 - outp - ETA: 15s - loss: 52.7530 - output_0_loss: 18.4232 - output_1_loss: 17.34\n",
      "Epoch 00061: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.18 (0%:  0.00, 5%:  0.45, 25%:  1.02, 50%:  1.57, 75%:  2.25, 95%:  5.17, 100%: 64.36) \n",
      "confidence - mean:  0.73 (0%:  0.09, 5%:  0.52, 25%:  0.66, 50%:  0.74, 75%:  0.83, 95%:  0.93, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 75s 899ms/step - loss: 52.6992 - output_0_loss: 18.4060 - output_1_loss: 17.3223 - output_2_loss: 16.9709 - val_loss: 47.6906 - val_output_0_loss: 16.6113 - val_output_1_loss: 15.7587 - val_output_2_loss: 15.3207\n",
      "Epoch 62/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 52.0573 - output_0_loss: 18.1154 - output_1_loss: 17.1377 - output_2_loss: 16.8042\n",
      "Epoch 00062: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.27 (0%:  0.00, 5%:  0.49, 25%:  1.13, 50%:  1.69, 75%:  2.44, 95%:  5.30, 100%: 56.81) \n",
      "confidence - mean:  0.74 (0%:  0.07, 5%:  0.51, 25%:  0.66, 50%:  0.74, 75%:  0.84, 95%:  0.94, 100%:  1.11) \n",
      "\n",
      "84/84 [==============================] - 76s 900ms/step - loss: 51.9819 - output_0_loss: 18.0889 - output_1_loss: 17.1130 - output_2_loss: 16.7800 - val_loss: 50.4252 - val_output_0_loss: 17.7227 - val_output_1_loss: 16.5285 - val_output_2_loss: 16.1739\n",
      "Epoch 63/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.6303 - output_0_loss: 17.6763 - output_1_loss: 16.6373 - output_2_loss: 16.3167\n",
      "Epoch 00063: val_loss did not improve from 45.27150\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.25 (0%:  0.00, 5%:  0.47, 25%:  1.04, 50%:  1.56, 75%:  2.24, 95%:  5.51, 100%: 60.99) \n",
      "confidence - mean:  0.74 (0%:  0.11, 5%:  0.51, 25%:  0.65, 50%:  0.74, 75%:  0.84, 95%:  0.96, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 68s 813ms/step - loss: 50.6457 - output_0_loss: 17.6852 - output_1_loss: 16.6410 - output_2_loss: 16.3195 - val_loss: 47.4056 - val_output_0_loss: 16.5277 - val_output_1_loss: 15.5333 - val_output_2_loss: 15.3446\n",
      "Epoch 64/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.9847 - output_0_loss: 17.7984 - output_1_loss: 16.7606 - output_2_loss: 16.4258\n",
      "Epoch 00064: val_loss improved from 45.27150 to 45.24200, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.11 (0%:  0.00, 5%:  0.47, 25%:  1.04, 50%:  1.54, 75%:  2.19, 95%:  5.15, 100%: 56.46) \n",
      "confidence - mean:  0.76 (0%:  0.06, 5%:  0.53, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 50.9216 - output_0_loss: 17.7754 - output_1_loss: 16.7401 - output_2_loss: 16.4061 - val_loss: 45.2420 - val_output_0_loss: 15.8399 - val_output_1_loss: 14.8828 - val_output_2_loss: 14.5193\n",
      "Epoch 65/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 51.3685 - output_0_loss: 17.9109 - output_1_loss: 16.8978 - output_2_loss: 16.5598\n",
      "Epoch 00065: val_loss improved from 45.24200 to 44.82762, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.10 (0%:  0.00, 5%:  0.43, 25%:  1.00, 50%:  1.50, 75%:  2.14, 95%:  5.30, 100%: 60.99) \n",
      "confidence - mean:  0.74 (0%:  0.06, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 73s 871ms/step - loss: 51.3781 - output_0_loss: 17.9158 - output_1_loss: 16.9019 - output_2_loss: 16.5604 - val_loss: 44.8276 - val_output_0_loss: 15.8310 - val_output_1_loss: 14.6646 - val_output_2_loss: 14.3320\n",
      "Epoch 66/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.6203 - output_0_loss: 17.6910 - output_1_loss: 16.6486 - output_2_loss: 16.2807\n",
      "Epoch 00066: val_loss did not improve from 44.82762\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.18 (0%:  0.00, 5%:  0.47, 25%:  1.09, 50%:  1.62, 75%:  2.26, 95%:  5.18, 100%: 50.44) \n",
      "confidence - mean:  0.74 (0%:  0.06, 5%:  0.52, 25%:  0.66, 50%:  0.75, 75%:  0.84, 95%:  0.93, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 73s 867ms/step - loss: 50.5877 - output_0_loss: 17.6835 - output_1_loss: 16.6365 - output_2_loss: 16.2677 - val_loss: 47.5314 - val_output_0_loss: 16.4777 - val_output_1_loss: 15.6020 - val_output_2_loss: 15.4517\n",
      "Epoch 67/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 51.2493 - output_0_loss: 17.8997 - output_1_loss: 16.8548 - output_2_loss: 16.4947  ETA: 20s - loss: 50.8720 - output_0_loss: 17.7338 - outpu\n",
      "Epoch 00067: val_loss did not improve from 44.82762\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.26 (0%:  0.04, 5%:  0.50, 25%:  1.06, 50%:  1.61, 75%:  2.29, 95%:  5.45, 100%: 67.01) \n",
      "confidence - mean:  0.75 (0%:  0.04, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.85, 95%:  0.95, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 73s 870ms/step - loss: 51.2816 - output_0_loss: 17.9133 - output_1_loss: 16.8645 - output_2_loss: 16.5038 - val_loss: 50.2186 - val_output_0_loss: 17.1579 - val_output_1_loss: 16.6946 - val_output_2_loss: 16.3661\n",
      "Epoch 68/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 51.2798 - output_0_loss: 17.8734 - output_1_loss: 16.8789 - output_2_loss: 16.5275\n",
      "Epoch 00068: val_loss improved from 44.82762 to 42.42029, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.00 (0%:  0.00, 5%:  0.41, 25%:  0.95, 50%:  1.44, 75%:  2.08, 95%:  4.87, 100%: 46.02) \n",
      "confidence - mean:  0.75 (0%:  0.10, 5%:  0.52, 25%:  0.67, 50%:  0.75, 75%:  0.84, 95%:  0.95, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 70s 836ms/step - loss: 51.2303 - output_0_loss: 17.8553 - output_1_loss: 16.8627 - output_2_loss: 16.5123 - val_loss: 42.4203 - val_output_0_loss: 14.8189 - val_output_1_loss: 13.9517 - val_output_2_loss: 13.6497\n",
      "Epoch 69/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.0348 - output_0_loss: 17.4718 - output_1_loss: 16.4598 - output_2_loss: 16.1032\n",
      "Epoch 00069: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.13 (0%:  0.04, 5%:  0.43, 25%:  0.96, 50%:  1.45, 75%:  2.16, 95%:  5.04, 100%: 92.67) \n",
      "confidence - mean:  0.75 (0%:  0.05, 5%:  0.52, 25%:  0.67, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 70s 832ms/step - loss: 50.0731 - output_0_loss: 17.4871 - output_1_loss: 16.4724 - output_2_loss: 16.1136 - val_loss: 44.4704 - val_output_0_loss: 15.4473 - val_output_1_loss: 14.7378 - val_output_2_loss: 14.2852\n",
      "Epoch 70/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.1016 - output_0_loss: 17.4800 - output_1_loss: 16.4846 - output_2_loss: 16.1370  ETA: 16s - loss: 49.1594 - output_0_loss: 17.1554 - output_1_los\n",
      "Epoch 00070: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.22 (0%:  0.00, 5%:  0.47, 25%:  1.04, 50%:  1.56, 75%:  2.24, 95%:  5.61, 100%: 58.24) \n",
      "confidence - mean:  0.72 (0%:  0.11, 5%:  0.48, 25%:  0.64, 50%:  0.73, 75%:  0.82, 95%:  0.91, 100%:  1.01) \n",
      "\n",
      "84/84 [==============================] - 69s 824ms/step - loss: 50.3264 - output_0_loss: 17.5549 - output_1_loss: 16.5584 - output_2_loss: 16.2131 - val_loss: 50.1544 - val_output_0_loss: 17.4223 - val_output_1_loss: 16.4928 - val_output_2_loss: 16.2393\n",
      "Epoch 71/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.9451 - output_0_loss: 17.7665 - output_1_loss: 16.7658 - output_2_loss: 16.4128  ETA: 21s - loss: 50.2597 - output_0_loss: 17.5578 - ou\n",
      "Epoch 00071: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.03 (0%:  0.00, 5%:  0.44, 25%:  0.96, 50%:  1.43, 75%:  2.10, 95%:  4.91, 100%: 46.96) \n",
      "confidence - mean:  0.73 (0%:  0.05, 5%:  0.50, 25%:  0.66, 50%:  0.74, 75%:  0.83, 95%:  0.93, 100%:  1.09) \n",
      "\n",
      "84/84 [==============================] - 78s 924ms/step - loss: 50.9228 - output_0_loss: 17.7599 - output_1_loss: 16.7574 - output_2_loss: 16.4054 - val_loss: 44.9149 - val_output_0_loss: 15.7379 - val_output_1_loss: 14.7626 - val_output_2_loss: 14.4144\n",
      "Epoch 72/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.3560 - output_0_loss: 17.5453 - output_1_loss: 16.5760 - output_2_loss: 16.2347\n",
      "Epoch 00072: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.30 (0%:  0.04, 5%:  0.48, 25%:  1.08, 50%:  1.63, 75%:  2.33, 95%:  5.45, 100%: 60.98) \n",
      "confidence - mean:  0.74 (0%:  0.03, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.83, 95%:  0.92, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 72s 855ms/step - loss: 50.2722 - output_0_loss: 17.5170 - output_1_loss: 16.5481 - output_2_loss: 16.2072 - val_loss: 50.6909 - val_output_0_loss: 17.8490 - val_output_1_loss: 16.6292 - val_output_2_loss: 16.2128\n",
      "Epoch 73/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 48.5061 - output_0_loss: 16.9109 - output_1_loss: 15.9669 - output_2_loss: 15.6283\n",
      "Epoch 00073: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.00 (0%:  0.03, 5%:  0.37, 25%:  0.88, 50%:  1.33, 75%:  1.98, 95%:  5.18, 100%: 92.82) \n",
      "confidence - mean:  0.75 (0%:  0.08, 5%:  0.53, 25%:  0.67, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.08) \n",
      "\n",
      "84/84 [==============================] - 67s 795ms/step - loss: 48.6531 - output_0_loss: 16.9618 - output_1_loss: 16.0146 - output_2_loss: 15.6768 - val_loss: 42.5597 - val_output_0_loss: 14.6290 - val_output_1_loss: 14.0646 - val_output_2_loss: 13.8661\n",
      "Epoch 74/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.2143 - output_0_loss: 17.4730 - output_1_loss: 16.5366 - output_2_loss: 16.2047\n",
      "Epoch 00074: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.03 (0%:  0.00, 5%:  0.39, 25%:  0.91, 50%:  1.39, 75%:  2.02, 95%:  5.02, 100%: 50.42) \n",
      "confidence - mean:  0.74 (0%:  0.05, 5%:  0.52, 25%:  0.66, 50%:  0.74, 75%:  0.83, 95%:  0.92, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 79s 935ms/step - loss: 50.2337 - output_0_loss: 17.4774 - output_1_loss: 16.5429 - output_2_loss: 16.2134 - val_loss: 44.7242 - val_output_0_loss: 15.4140 - val_output_1_loss: 14.8428 - val_output_2_loss: 14.4674\n",
      "Epoch 75/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.1948 - output_0_loss: 17.4427 - output_1_loss: 16.5379 - output_2_loss: 16.2142\n",
      "Epoch 00075: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.24 (0%:  0.04, 5%:  0.48, 25%:  1.08, 50%:  1.62, 75%:  2.32, 95%:  5.29, 100%: 61.93) \n",
      "confidence - mean:  0.74 (0%:  0.03, 5%:  0.48, 25%:  0.66, 50%:  0.75, 75%:  0.83, 95%:  0.94, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 74s 882ms/step - loss: 50.1584 - output_0_loss: 17.4327 - output_1_loss: 16.5255 - output_2_loss: 16.2003 - val_loss: 49.1552 - val_output_0_loss: 16.9399 - val_output_1_loss: 16.3029 - val_output_2_loss: 15.9123\n",
      "Epoch 76/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.1685 - output_0_loss: 17.4514 - output_1_loss: 16.5371 - output_2_loss: 16.1800\n",
      "Epoch 00076: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.14 (0%:  0.01, 5%:  0.47, 25%:  1.04, 50%:  1.56, 75%:  2.24, 95%:  5.14, 100%: 55.64) \n",
      "confidence - mean:  0.75 (0%:  0.04, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 69s 822ms/step - loss: 50.2164 - output_0_loss: 17.4660 - output_1_loss: 16.5533 - output_2_loss: 16.1971 - val_loss: 45.7542 - val_output_0_loss: 15.9430 - val_output_1_loss: 15.0798 - val_output_2_loss: 14.7315\n",
      "Epoch 77/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.2803 - output_0_loss: 17.5007 - output_1_loss: 16.5530 - output_2_loss: 16.2267  ETA: 11s - loss: 50.1756 - output_0_loss: 17.4545 - output_1_loss: 16.5172 - output_2\n",
      "Epoch 00077: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.14 (0%:  0.00, 5%:  0.47, 25%:  1.06, 50%:  1.55, 75%:  2.20, 95%:  5.11, 100%: 83.11) \n",
      "confidence - mean:  0.74 (0%:  0.04, 5%:  0.52, 25%:  0.66, 50%:  0.74, 75%:  0.83, 95%:  0.93, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 73s 864ms/step - loss: 50.2316 - output_0_loss: 17.4844 - output_1_loss: 16.5373 - output_2_loss: 16.2099 - val_loss: 46.4151 - val_output_0_loss: 15.8836 - val_output_1_loss: 15.3619 - val_output_2_loss: 15.1697\n",
      "Epoch 78/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 48.9793 - output_0_loss: 17.1092 - output_1_loss: 16.1167 - output_2_loss: 15.7534\n",
      "Epoch 00078: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.09 (0%:  0.00, 5%:  0.43, 25%:  0.96, 50%:  1.48, 75%:  2.12, 95%:  5.12, 100%: 52.38) \n",
      "confidence - mean:  0.75 (0%:  0.03, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.93, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 845ms/step - loss: 48.9841 - output_0_loss: 17.1116 - output_1_loss: 16.1177 - output_2_loss: 15.7548 - val_loss: 43.8853 - val_output_0_loss: 15.2959 - val_output_1_loss: 14.4626 - val_output_2_loss: 14.1268\n",
      "Epoch 79/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 49.1812 - output_0_loss: 17.1113 - output_1_loss: 16.1987 - output_2_loss: 15.8712\n",
      "Epoch 00079: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.11 (0%:  0.00, 5%:  0.41, 25%:  0.97, 50%:  1.47, 75%:  2.12, 95%:  5.15, 100%: 49.52) \n",
      "confidence - mean:  0.74 (0%:  0.08, 5%:  0.52, 25%:  0.66, 50%:  0.75, 75%:  0.83, 95%:  0.93, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 840ms/step - loss: 49.2599 - output_0_loss: 17.1376 - output_1_loss: 16.2241 - output_2_loss: 15.8982 - val_loss: 44.9789 - val_output_0_loss: 15.9619 - val_output_1_loss: 14.8009 - val_output_2_loss: 14.2160\n",
      "Epoch 80/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 49.7083 - output_0_loss: 17.3511 - output_1_loss: 16.3447 - output_2_loss: 16.0126\n",
      "Epoch 00080: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.05 (0%:  0.04, 5%:  0.43, 25%:  0.96, 50%:  1.45, 75%:  2.11, 95%:  5.09, 100%: 46.00) \n",
      "confidence - mean:  0.74 (0%:  0.05, 5%:  0.51, 25%:  0.66, 50%:  0.75, 75%:  0.84, 95%:  0.93, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 73s 868ms/step - loss: 49.6077 - output_0_loss: 17.3164 - output_1_loss: 16.3113 - output_2_loss: 15.9800 - val_loss: 45.3789 - val_output_0_loss: 15.7442 - val_output_1_loss: 15.0211 - val_output_2_loss: 14.6135\n",
      "Epoch 81/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 48.7054 - output_0_loss: 16.9863 - output_1_loss: 16.0222 - output_2_loss: 15.6969\n",
      "Epoch 00081: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.22 (0%:  0.00, 5%:  0.52, 25%:  1.13, 50%:  1.64, 75%:  2.27, 95%:  5.36, 100%: 54.03) \n",
      "confidence - mean:  0.75 (0%:  0.04, 5%:  0.52, 25%:  0.67, 50%:  0.75, 75%:  0.84, 95%:  0.95, 100%:  1.06) \n",
      "\n",
      "84/84 [==============================] - 78s 931ms/step - loss: 48.5618 - output_0_loss: 16.9377 - output_1_loss: 15.9738 - output_2_loss: 15.6503 - val_loss: 47.6547 - val_output_0_loss: 16.5743 - val_output_1_loss: 15.7016 - val_output_2_loss: 15.3789\n",
      "Epoch 82/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 49.6139 - output_0_loss: 17.2816 - output_1_loss: 16.3414 - output_2_loss: 15.9909- ETA: 1s - loss: 49.6158 - output_0_loss: 17.2813 - output_1_loss: 16.3422 - output_2_loss: 15.992\n",
      "Epoch 00082: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.23 (0%:  0.04, 5%:  0.52, 25%:  1.13, 50%:  1.66, 75%:  2.33, 95%:  5.26, 100%: 52.94) \n",
      "confidence - mean:  0.74 (0%:  0.08, 5%:  0.53, 25%:  0.66, 50%:  0.75, 75%:  0.84, 95%:  0.93, 100%:  1.01) \n",
      "\n",
      "84/84 [==============================] - 74s 881ms/step - loss: 49.5361 - output_0_loss: 17.2530 - output_1_loss: 16.3163 - output_2_loss: 15.9668 - val_loss: 47.4651 - val_output_0_loss: 16.4046 - val_output_1_loss: 15.7272 - val_output_2_loss: 15.3333\n",
      "Epoch 83/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 49.1452 - output_0_loss: 17.1113 - output_1_loss: 16.1687 - output_2_loss: 15.8651\n",
      "Epoch 00083: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.14 (0%:  0.04, 5%:  0.49, 25%:  1.08, 50%:  1.58, 75%:  2.19, 95%:  5.17, 100%: 51.91) \n",
      "confidence - mean:  0.76 (0%:  0.08, 5%:  0.53, 25%:  0.68, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 49.0952 - output_0_loss: 17.0990 - output_1_loss: 16.1509 - output_2_loss: 15.8452 - val_loss: 46.6440 - val_output_0_loss: 16.1161 - val_output_1_loss: 15.4122 - val_output_2_loss: 15.1157\n",
      "Epoch 84/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 49.0625 - output_0_loss: 17.1249 - output_1_loss: 16.1409 - output_2_loss: 15.7968\n",
      "Epoch 00084: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.04 (0%:  0.00, 5%:  0.41, 25%:  0.96, 50%:  1.47, 75%:  2.10, 95%:  5.18, 100%: 84.21) \n",
      "confidence - mean:  0.75 (0%:  0.05, 5%:  0.53, 25%:  0.66, 50%:  0.75, 75%:  0.85, 95%:  0.95, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 71s 842ms/step - loss: 48.9318 - output_0_loss: 17.0780 - output_1_loss: 16.0982 - output_2_loss: 15.7556 - val_loss: 44.7407 - val_output_0_loss: 15.4171 - val_output_1_loss: 14.7864 - val_output_2_loss: 14.5372\n",
      "Epoch 85/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 48.7692 - output_0_loss: 16.9983 - output_1_loss: 16.0585 - output_2_loss: 15.7123\n",
      "Epoch 00085: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.16 (0%:  0.00, 5%:  0.45, 25%:  0.97, 50%:  1.48, 75%:  2.13, 95%:  5.18, 100%: 82.92) \n",
      "confidence - mean:  0.74 (0%:  0.03, 5%:  0.52, 25%:  0.67, 50%:  0.75, 75%:  0.84, 95%:  0.94, 100%:  1.07) \n",
      "\n",
      "84/84 [==============================] - 72s 859ms/step - loss: 48.7564 - output_0_loss: 16.9951 - output_1_loss: 16.0539 - output_2_loss: 15.7074 - val_loss: 45.6515 - val_output_0_loss: 15.9706 - val_output_1_loss: 15.0308 - val_output_2_loss: 14.6501\n",
      "Epoch 86/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 48.5759 - output_0_loss: 16.9050 - output_1_loss: 15.9974 - output_2_loss: 15.6735\n",
      "Epoch 00086: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.09 (0%:  0.04, 5%:  0.43, 25%:  1.01, 50%:  1.53, 75%:  2.16, 95%:  5.02, 100%: 84.46) \n",
      "confidence - mean:  0.74 (0%:  0.05, 5%:  0.52, 25%:  0.66, 50%:  0.74, 75%:  0.83, 95%:  0.93, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 69s 817ms/step - loss: 48.5914 - output_0_loss: 16.9085 - output_1_loss: 16.0019 - output_2_loss: 15.6810 - val_loss: 44.1437 - val_output_0_loss: 15.3728 - val_output_1_loss: 14.5467 - val_output_2_loss: 14.2242\n",
      "Epoch 87/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 49.3890 - output_0_loss: 17.1876 - output_1_loss: 16.2608 - output_2_loss: 15.9407\n",
      "Epoch 00087: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.30 (0%:  0.04, 5%:  0.47, 25%:  1.08, 50%:  1.63, 75%:  2.37, 95%:  5.60, 100%: 58.79) \n",
      "confidence - mean:  0.75 (0%:  0.10, 5%:  0.54, 25%:  0.67, 50%:  0.75, 75%:  0.85, 95%:  0.93, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 75s 890ms/step - loss: 49.3899 - output_0_loss: 17.1869 - output_1_loss: 16.2621 - output_2_loss: 15.9410 - val_loss: 49.5564 - val_output_0_loss: 16.9988 - val_output_1_loss: 16.3767 - val_output_2_loss: 16.1809\n",
      "Epoch 88/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 48.6221 - output_0_loss: 16.9016 - output_1_loss: 16.0249 - output_2_loss: 15.6956\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.18 (0%:  0.00, 5%:  0.49, 25%:  1.05, 50%:  1.56, 75%:  2.24, 95%:  5.37, 100%: 54.65) \n",
      "confidence - mean:  0.75 (0%:  0.03, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 72s 853ms/step - loss: 48.4641 - output_0_loss: 16.8482 - output_1_loss: 15.9726 - output_2_loss: 15.6433 - val_loss: 47.7391 - val_output_0_loss: 16.4736 - val_output_1_loss: 15.7799 - val_output_2_loss: 15.4855\n",
      "Epoch 89/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 46.3483 - output_0_loss: 16.1856 - output_1_loss: 15.2498 - output_2_loss: 14.9129  ETA: 15s - loss: 44.8277 - output_0_loss: 15.6980 - ETA: 39s\n",
      "Epoch 00089: val_loss did not improve from 42.42029\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.11 (0%:  0.06, 5%:  0.49, 25%:  1.07, 50%:  1.58, 75%:  2.19, 95%:  5.00, 100%: 50.20) \n",
      "confidence - mean:  0.76 (0%:  0.06, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 78s 931ms/step - loss: 46.1860 - output_0_loss: 16.1297 - output_1_loss: 15.1968 - output_2_loss: 14.8595 - val_loss: 44.1250 - val_output_0_loss: 15.1798 - val_output_1_loss: 14.5661 - val_output_2_loss: 14.3791\n",
      "Epoch 90/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 44.2015 - output_0_loss: 15.4655 - output_1_loss: 14.5361 - output_2_loss: 14.2000\n",
      "Epoch 00090: val_loss improved from 42.42029 to 40.11853, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.41, 25%:  0.96, 50%:  1.43, 75%:  2.01, 95%:  4.81, 100%: 44.09) \n",
      "confidence - mean:  0.76 (0%:  0.14, 5%:  0.56, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 72s 863ms/step - loss: 44.2448 - output_0_loss: 15.4817 - output_1_loss: 14.5495 - output_2_loss: 14.2137 - val_loss: 40.1185 - val_output_0_loss: 13.8880 - val_output_1_loss: 13.1988 - val_output_2_loss: 13.0317\n",
      "Epoch 91/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 43.2117 - output_0_loss: 15.1245 - output_1_loss: 14.2119 - output_2_loss: 13.8753\n",
      "Epoch 00091: val_loss improved from 40.11853 to 39.39573, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.04, 5%:  0.40, 25%:  0.91, 50%:  1.38, 75%:  1.94, 95%:  4.87, 100%: 51.30) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.54, 25%:  0.68, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 75s 898ms/step - loss: 43.3142 - output_0_loss: 15.1576 - output_1_loss: 14.2449 - output_2_loss: 13.9118 - val_loss: 39.3957 - val_output_0_loss: 13.6367 - val_output_1_loss: 13.0076 - val_output_2_loss: 12.7514\n",
      "Epoch 92/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 43.0113 - output_0_loss: 15.0769 - output_1_loss: 14.1423 - output_2_loss: 13.7921\n",
      "Epoch 00092: val_loss improved from 39.39573 to 38.49763, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.90 (0%:  0.00, 5%:  0.39, 25%:  0.88, 50%:  1.35, 75%:  1.93, 95%:  4.72, 100%: 52.45) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 71s 851ms/step - loss: 42.9955 - output_0_loss: 15.0715 - output_1_loss: 14.1373 - output_2_loss: 13.7866 - val_loss: 38.4976 - val_output_0_loss: 13.3814 - val_output_1_loss: 12.6852 - val_output_2_loss: 12.4310\n",
      "Epoch 93/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 43.5391 - output_0_loss: 15.2344 - output_1_loss: 14.3222 - output_2_loss: 13.9824\n",
      "Epoch 00093: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.02 (0%:  0.00, 5%:  0.44, 25%:  1.00, 50%:  1.48, 75%:  2.08, 95%:  4.86, 100%: 52.11) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 73s 866ms/step - loss: 43.6086 - output_0_loss: 15.2645 - output_1_loss: 14.3435 - output_2_loss: 14.0006 - val_loss: 42.2589 - val_output_0_loss: 14.4799 - val_output_1_loss: 14.0001 - val_output_2_loss: 13.7789\n",
      "Epoch 94/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 43.4104 - output_0_loss: 15.2127 - output_1_loss: 14.2663 - output_2_loss: 13.9314\n",
      "Epoch 00094: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.00 (0%:  0.00, 5%:  0.45, 25%:  0.97, 50%:  1.46, 75%:  2.03, 95%:  4.97, 100%: 49.93) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 848ms/step - loss: 43.4292 - output_0_loss: 15.2224 - output_1_loss: 14.2722 - output_2_loss: 13.9346 - val_loss: 41.7865 - val_output_0_loss: 14.3878 - val_output_1_loss: 13.8041 - val_output_2_loss: 13.5946\n",
      "Epoch 95/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 43.0490 - output_0_loss: 15.0619 - output_1_loss: 14.1533 - output_2_loss: 13.8338\n",
      "Epoch 00095: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.02 (0%:  0.00, 5%:  0.47, 25%:  1.01, 50%:  1.49, 75%:  2.07, 95%:  4.81, 100%: 47.95) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 74s 878ms/step - loss: 43.0467 - output_0_loss: 15.0599 - output_1_loss: 14.1527 - output_2_loss: 13.8340 - val_loss: 40.9354 - val_output_0_loss: 14.1964 - val_output_1_loss: 13.4893 - val_output_2_loss: 13.2497\n",
      "Epoch 96/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.6565 - output_0_loss: 14.9417 - output_1_loss: 14.0245 - output_2_loss: 13.6903\n",
      "Epoch 00096: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.00 (0%:  0.00, 5%:  0.44, 25%:  0.97, 50%:  1.45, 75%:  2.03, 95%:  4.93, 100%: 53.53) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 841ms/step - loss: 42.7365 - output_0_loss: 14.9646 - output_1_loss: 14.0524 - output_2_loss: 13.7195 - val_loss: 41.0350 - val_output_0_loss: 14.1225 - val_output_1_loss: 13.5422 - val_output_2_loss: 13.3704\n",
      "Epoch 97/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 43.0320 - output_0_loss: 15.0603 - output_1_loss: 14.1573 - output_2_loss: 13.8144\n",
      "Epoch 00097: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.01 (0%:  0.00, 5%:  0.45, 25%:  0.97, 50%:  1.46, 75%:  2.02, 95%:  5.09, 100%: 49.35) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 68s 815ms/step - loss: 43.0158 - output_0_loss: 15.0531 - output_1_loss: 14.1522 - output_2_loss: 13.8105 - val_loss: 40.9560 - val_output_0_loss: 14.1082 - val_output_1_loss: 13.4977 - val_output_2_loss: 13.3501\n",
      "Epoch 98/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.3131 - output_0_loss: 14.8169 - output_1_loss: 13.9119 - output_2_loss: 13.5843  ETA: 21s - loss: 41.9056 - output_0_loss: 14.6839 - out\n",
      "Epoch 00098: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.06 (0%:  0.00, 5%:  0.49, 25%:  1.03, 50%:  1.53, 75%:  2.12, 95%:  4.82, 100%: 55.46) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 72s 861ms/step - loss: 42.3763 - output_0_loss: 14.8421 - output_1_loss: 13.9333 - output_2_loss: 13.6009 - val_loss: 41.3708 - val_output_0_loss: 14.2716 - val_output_1_loss: 13.6469 - val_output_2_loss: 13.4523\n",
      "Epoch 99/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.2244 - output_0_loss: 14.7865 - output_1_loss: 13.8842 - output_2_loss: 13.5538\n",
      "Epoch 00099: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.00, 5%:  0.44, 25%:  0.97, 50%:  1.46, 75%:  2.05, 95%:  4.76, 100%: 51.01) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 66s 789ms/step - loss: 42.1685 - output_0_loss: 14.7678 - output_1_loss: 13.8652 - output_2_loss: 13.5355 - val_loss: 40.5108 - val_output_0_loss: 13.9679 - val_output_1_loss: 13.3611 - val_output_2_loss: 13.1818\n",
      "Epoch 100/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.1266 - output_0_loss: 14.7541 - output_1_loss: 13.8540 - output_2_loss: 13.5185\n",
      "Epoch 00100: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.91, 50%:  1.38, 75%:  1.94, 95%:  4.63, 100%: 51.78) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.55, 25%:  0.68, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 840ms/step - loss: 42.2135 - output_0_loss: 14.7861 - output_1_loss: 13.8838 - output_2_loss: 13.5436 - val_loss: 38.6625 - val_output_0_loss: 13.4340 - val_output_1_loss: 12.7270 - val_output_2_loss: 12.5015\n",
      "Epoch 101/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.4115 - output_0_loss: 14.8701 - output_1_loss: 13.9453 - output_2_loss: 13.5960\n",
      "Epoch 00101: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.89 (0%:  0.04, 5%:  0.38, 25%:  0.87, 50%:  1.33, 75%:  1.90, 95%:  4.70, 100%: 47.75) \n",
      "confidence - mean:  0.75 (0%:  0.06, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 811ms/step - loss: 42.4123 - output_0_loss: 14.8703 - output_1_loss: 13.9453 - output_2_loss: 13.5967 - val_loss: 38.9748 - val_output_0_loss: 13.5976 - val_output_1_loss: 12.8504 - val_output_2_loss: 12.5269\n",
      "Epoch 102/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.7311 - output_0_loss: 14.9772 - output_1_loss: 14.0526 - output_2_loss: 13.7013  ETA: 44s - loss: 42.0875 - output_0_loss: - ETA: 27s - loss: 43.7975 - output_0_loss: 15\n",
      "Epoch 00102: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.06 (0%:  0.00, 5%:  0.47, 25%:  1.04, 50%:  1.54, 75%:  2.12, 95%:  4.89, 100%: 43.32) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.56, 25%:  0.69, 50%:  0.76, 75%:  0.86, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 78s 933ms/step - loss: 42.7778 - output_0_loss: 14.9973 - output_1_loss: 14.0670 - output_2_loss: 13.7136 - val_loss: 41.7758 - val_output_0_loss: 14.3377 - val_output_1_loss: 13.8270 - val_output_2_loss: 13.6111\n",
      "Epoch 103/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.6297 - output_0_loss: 14.9457 - output_1_loss: 14.0110 - output_2_loss: 13.6730\n",
      "Epoch 00103: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.00, 5%:  0.43, 25%:  0.96, 50%:  1.42, 75%:  2.01, 95%:  4.91, 100%: 55.27) \n",
      "confidence - mean:  0.76 (0%:  0.06, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 70s 837ms/step - loss: 42.6221 - output_0_loss: 14.9394 - output_1_loss: 14.0093 - output_2_loss: 13.6735 - val_loss: 39.9970 - val_output_0_loss: 13.7777 - val_output_1_loss: 13.2311 - val_output_2_loss: 12.9882\n",
      "Epoch 104/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.7603 - output_0_loss: 14.9987 - output_1_loss: 14.0578 - output_2_loss: 13.7038\n",
      "Epoch 00104: val_loss did not improve from 38.49763\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.89 (0%:  0.00, 5%:  0.43, 25%:  0.89, 50%:  1.36, 75%:  1.93, 95%:  4.77, 100%: 42.40) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.87, 95%:  0.96, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 72s 859ms/step - loss: 42.6587 - output_0_loss: 14.9634 - output_1_loss: 14.0241 - output_2_loss: 13.6713 - val_loss: 38.6558 - val_output_0_loss: 13.3861 - val_output_1_loss: 12.7723 - val_output_2_loss: 12.4974\n",
      "Epoch 105/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.5254 - output_0_loss: 14.8788 - output_1_loss: 13.9841 - output_2_loss: 13.6625\n",
      "Epoch 00105: val_loss improved from 38.49763 to 38.19055, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.91, 50%:  1.38, 75%:  1.95, 95%:  4.76, 100%: 48.45) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.56, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 67s 803ms/step - loss: 42.5589 - output_0_loss: 14.8904 - output_1_loss: 13.9960 - output_2_loss: 13.6725 - val_loss: 38.1906 - val_output_0_loss: 13.2209 - val_output_1_loss: 12.5794 - val_output_2_loss: 12.3902\n",
      "Epoch 106/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.3526 - output_0_loss: 14.8670 - output_1_loss: 13.9219 - output_2_loss: 13.5637\n",
      "Epoch 00106: val_loss did not improve from 38.19055\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.43, 25%:  0.95, 50%:  1.41, 75%:  2.00, 95%:  4.78, 100%: 49.24) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 74s 883ms/step - loss: 42.3740 - output_0_loss: 14.8740 - output_1_loss: 13.9288 - output_2_loss: 13.5713 - val_loss: 38.5599 - val_output_0_loss: 13.3423 - val_output_1_loss: 12.7551 - val_output_2_loss: 12.4625\n",
      "Epoch 107/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.9112 - output_0_loss: 14.6986 - output_1_loss: 13.7805 - output_2_loss: 13.4322\n",
      "Epoch 00107: val_loss did not improve from 38.19055\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.43, 25%:  0.94, 50%:  1.41, 75%:  2.00, 95%:  4.61, 100%: 44.77) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 41.7869 - output_0_loss: 14.6593 - output_1_loss: 13.7381 - output_2_loss: 13.3895 - val_loss: 39.0463 - val_output_0_loss: 13.5503 - val_output_1_loss: 12.8674 - val_output_2_loss: 12.6286\n",
      "Epoch 108/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.7657 - output_0_loss: 14.9721 - output_1_loss: 14.0644 - output_2_loss: 13.7292\n",
      "Epoch 00108: val_loss improved from 38.19055 to 37.80336, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.87 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.36, 75%:  1.92, 95%:  4.52, 100%: 50.30) \n",
      "confidence - mean:  0.76 (0%:  0.05, 5%:  0.54, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 854ms/step - loss: 42.8054 - output_0_loss: 14.9857 - output_1_loss: 14.0769 - output_2_loss: 13.7428 - val_loss: 37.8034 - val_output_0_loss: 13.2045 - val_output_1_loss: 12.4244 - val_output_2_loss: 12.1744\n",
      "Epoch 109/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.6141 - output_0_loss: 14.9178 - output_1_loss: 14.0145 - output_2_loss: 13.6818\n",
      "Epoch 00109: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.41, 25%:  0.93, 50%:  1.41, 75%:  2.01, 95%:  4.57, 100%: 45.58) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.01) \n",
      "\n",
      "84/84 [==============================] - 67s 794ms/step - loss: 42.6040 - output_0_loss: 14.9145 - output_1_loss: 14.0111 - output_2_loss: 13.6784 - val_loss: 39.2440 - val_output_0_loss: 13.5554 - val_output_1_loss: 12.9553 - val_output_2_loss: 12.7333\n",
      "Epoch 110/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.0036 - output_0_loss: 14.7317 - output_1_loss: 13.7991 - output_2_loss: 13.4728\n",
      "Epoch 00110: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.00, 5%:  0.43, 25%:  0.97, 50%:  1.44, 75%:  2.04, 95%:  4.77, 100%: 46.84) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.56, 25%:  0.69, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 834ms/step - loss: 41.9737 - output_0_loss: 14.7239 - output_1_loss: 13.7877 - output_2_loss: 13.4621 - val_loss: 39.8550 - val_output_0_loss: 13.7072 - val_output_1_loss: 13.1960 - val_output_2_loss: 12.9518\n",
      "Epoch 111/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.6324 - output_0_loss: 14.6153 - output_1_loss: 13.6822 - output_2_loss: 13.3348\n",
      "Epoch 00111: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.41, 25%:  0.93, 50%:  1.40, 75%:  1.99, 95%:  4.75, 100%: 44.12) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.55, 25%:  0.69, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 870ms/step - loss: 41.6984 - output_0_loss: 14.6330 - output_1_loss: 13.7051 - output_2_loss: 13.3603 - val_loss: 39.9615 - val_output_0_loss: 13.7055 - val_output_1_loss: 13.2179 - val_output_2_loss: 13.0381\n",
      "Epoch 112/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.3105 - output_0_loss: 14.8103 - output_1_loss: 13.9174 - output_2_loss: 13.5828- ETA: 6s - loss: 42.4568 - output_0_loss: 14.8617 - output_1_loss: 13.9642 - output_2_loss:\n",
      "Epoch 00112: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.98 (0%:  0.06, 5%:  0.45, 25%:  1.00, 50%:  1.46, 75%:  2.06, 95%:  4.73, 100%: 44.41) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.56, 25%:  0.69, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 860ms/step - loss: 42.2478 - output_0_loss: 14.7909 - output_1_loss: 13.8958 - output_2_loss: 13.5611 - val_loss: 39.9296 - val_output_0_loss: 13.7418 - val_output_1_loss: 13.1696 - val_output_2_loss: 13.0182\n",
      "Epoch 113/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.4280 - output_0_loss: 14.8760 - output_1_loss: 13.9462 - output_2_loss: 13.6058  ETA: 35s - loss: 42.3 - ETA: 10s - loss: 42.2954 - output_0_loss: 14.8255 - output_1_loss: 13.9022 - output_\n",
      "Epoch 00113: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.01 (0%:  0.04, 5%:  0.45, 25%:  0.97, 50%:  1.45, 75%:  2.06, 95%:  4.94, 100%: 44.30) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 71s 845ms/step - loss: 42.5234 - output_0_loss: 14.9062 - output_1_loss: 13.9789 - output_2_loss: 13.6384 - val_loss: 41.3605 - val_output_0_loss: 14.1953 - val_output_1_loss: 13.6899 - val_output_2_loss: 13.4753\n",
      "Epoch 114/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.3635 - output_0_loss: 14.4978 - output_1_loss: 13.6032 - output_2_loss: 13.2624\n",
      "Epoch 00114: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.00 (0%:  0.00, 5%:  0.45, 25%:  0.97, 50%:  1.45, 75%:  2.04, 95%:  4.89, 100%: 43.58) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 70s 828ms/step - loss: 41.4215 - output_0_loss: 14.5191 - output_1_loss: 13.6230 - output_2_loss: 13.2794 - val_loss: 40.5539 - val_output_0_loss: 13.9232 - val_output_1_loss: 13.4049 - val_output_2_loss: 13.2257\n",
      "Epoch 115/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.4110 - output_0_loss: 14.5248 - output_1_loss: 13.6063 - output_2_loss: 13.2799\n",
      "Epoch 00115: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.05 (0%:  0.04, 5%:  0.47, 25%:  1.02, 50%:  1.50, 75%:  2.09, 95%:  4.89, 100%: 49.76) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.68, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 69s 822ms/step - loss: 41.4278 - output_0_loss: 14.5298 - output_1_loss: 13.6129 - output_2_loss: 13.2852 - val_loss: 41.6738 - val_output_0_loss: 14.2963 - val_output_1_loss: 13.7772 - val_output_2_loss: 13.6003\n",
      "Epoch 116/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 42.1468 - output_0_loss: 14.7952 - output_1_loss: 13.8493 - output_2_loss: 13.5024\n",
      "Epoch 00116: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.40, 25%:  0.92, 50%:  1.39, 75%:  2.00, 95%:  4.71, 100%: 51.75) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.96, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 850ms/step - loss: 42.0904 - output_0_loss: 14.7767 - output_1_loss: 13.8296 - output_2_loss: 13.4840 - val_loss: 38.9597 - val_output_0_loss: 13.4949 - val_output_1_loss: 12.8555 - val_output_2_loss: 12.6094\n",
      "Epoch 117/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.3975 - output_0_loss: 14.4985 - output_1_loss: 13.6121 - output_2_loss: 13.2868\n",
      "Epoch 00117: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.41, 25%:  0.93, 50%:  1.41, 75%:  1.99, 95%:  4.64, 100%: 49.91) \n",
      "confidence - mean:  0.77 (0%:  0.04, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 68s 812ms/step - loss: 41.5538 - output_0_loss: 14.5501 - output_1_loss: 13.6638 - output_2_loss: 13.3399 - val_loss: 38.8865 - val_output_0_loss: 13.4460 - val_output_1_loss: 12.8242 - val_output_2_loss: 12.6163\n",
      "Epoch 118/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.0371 - output_0_loss: 14.4312 - output_1_loss: 13.4798 - output_2_loss: 13.1261\n",
      "Epoch 00118: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.00 (0%:  0.06, 5%:  0.45, 25%:  0.99, 50%:  1.47, 75%:  2.06, 95%:  4.91, 100%: 43.46) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 71s 847ms/step - loss: 41.0560 - output_0_loss: 14.4373 - output_1_loss: 13.4861 - output_2_loss: 13.1326 - val_loss: 41.1434 - val_output_0_loss: 14.1278 - val_output_1_loss: 13.5986 - val_output_2_loss: 13.4170\n",
      "Epoch 119/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.1826 - output_0_loss: 14.4845 - output_1_loss: 13.5235 - output_2_loss: 13.1746  ETA: 27s - loss: 41.0400 - output_0_los\n",
      "Epoch 00119: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.44, 25%:  0.94, 50%:  1.42, 75%:  2.00, 95%:  4.56, 100%: 42.78) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.56, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.94, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 872ms/step - loss: 41.1642 - output_0_loss: 14.4778 - output_1_loss: 13.5187 - output_2_loss: 13.1678 - val_loss: 38.8905 - val_output_0_loss: 13.5160 - val_output_1_loss: 12.8184 - val_output_2_loss: 12.5561\n",
      "Epoch 120/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.5405 - output_0_loss: 14.5980 - output_1_loss: 13.6499 - output_2_loss: 13.2926\n",
      "Epoch 00120: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.04, 5%:  0.43, 25%:  0.93, 50%:  1.40, 75%:  2.01, 95%:  4.90, 100%: 41.69) \n",
      "confidence - mean:  0.76 (0%:  0.05, 5%:  0.55, 25%:  0.68, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 73s 872ms/step - loss: 41.4963 - output_0_loss: 14.5822 - output_1_loss: 13.6360 - output_2_loss: 13.2781 - val_loss: 40.2190 - val_output_0_loss: 13.8926 - val_output_1_loss: 13.3075 - val_output_2_loss: 13.0190\n",
      "Epoch 121/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.1985 - output_0_loss: 14.4575 - output_1_loss: 13.5415 - output_2_loss: 13.1995\n",
      "Epoch 00121: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.45, 25%:  0.95, 50%:  1.42, 75%:  2.01, 95%:  4.79, 100%: 43.67) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.05) \n",
      "\n",
      "84/84 [==============================] - 71s 851ms/step - loss: 41.2999 - output_0_loss: 14.4915 - output_1_loss: 13.5752 - output_2_loss: 13.2332 - val_loss: 39.6409 - val_output_0_loss: 13.6722 - val_output_1_loss: 13.0806 - val_output_2_loss: 12.8880\n",
      "Epoch 122/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.8864 - output_0_loss: 14.7112 - output_1_loss: 13.7600 - output_2_loss: 13.4152\n",
      "Epoch 00122: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.04 (0%:  0.04, 5%:  0.48, 25%:  1.03, 50%:  1.51, 75%:  2.10, 95%:  4.89, 100%: 43.11) \n",
      "confidence - mean:  0.75 (0%:  0.02, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 835ms/step - loss: 41.7625 - output_0_loss: 14.6699 - output_1_loss: 13.7195 - output_2_loss: 13.3731 - val_loss: 42.3193 - val_output_0_loss: 14.5629 - val_output_1_loss: 13.9869 - val_output_2_loss: 13.7695\n",
      "Epoch 123/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.6043 - output_0_loss: 14.5996 - output_1_loss: 13.6741 - output_2_loss: 13.3307\n",
      "Epoch 00123: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.03 (0%:  0.00, 5%:  0.48, 25%:  1.00, 50%:  1.50, 75%:  2.11, 95%:  4.87, 100%: 41.56) \n",
      "confidence - mean:  0.76 (0%:  0.04, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.01) \n",
      "\n",
      "84/84 [==============================] - 71s 842ms/step - loss: 41.5838 - output_0_loss: 14.5931 - output_1_loss: 13.6672 - output_2_loss: 13.3235 - val_loss: 41.8677 - val_output_0_loss: 14.4017 - val_output_1_loss: 13.8233 - val_output_2_loss: 13.6428\n",
      "Epoch 124/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.3073 - output_0_loss: 14.5238 - output_1_loss: 13.5731 - output_2_loss: 13.2105\n",
      "Epoch 00124: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.34, 75%:  1.94, 95%:  4.77, 100%: 45.48) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.96, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 813ms/step - loss: 41.4971 - output_0_loss: 14.5922 - output_1_loss: 13.6351 - output_2_loss: 13.2697 - val_loss: 38.3960 - val_output_0_loss: 13.1887 - val_output_1_loss: 12.7102 - val_output_2_loss: 12.4972\n",
      "Epoch 125/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.3838 - output_0_loss: 14.5214 - output_1_loss: 13.6008 - output_2_loss: 13.2616  ETA: 28s - loss: 42.0243 - output_0_l\n",
      "Epoch 00125: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.08, 5%:  0.40, 25%:  0.91, 50%:  1.38, 75%:  1.95, 95%:  4.79, 100%: 42.27) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.56, 25%:  0.68, 50%:  0.76, 75%:  0.85, 95%:  0.94, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 74s 877ms/step - loss: 41.4210 - output_0_loss: 14.5315 - output_1_loss: 13.6143 - output_2_loss: 13.2752 - val_loss: 38.5707 - val_output_0_loss: 13.3297 - val_output_1_loss: 12.7224 - val_output_2_loss: 12.5186\n",
      "Epoch 126/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.2545 - output_0_loss: 14.5097 - output_1_loss: 13.5529 - output_2_loss: 13.1920\n",
      "Epoch 00126: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.04 (0%:  0.00, 5%:  0.49, 25%:  1.05, 50%:  1.52, 75%:  2.12, 95%:  4.81, 100%: 43.38) \n",
      "confidence - mean:  0.77 (0%:  0.01, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 71s 848ms/step - loss: 41.2670 - output_0_loss: 14.5125 - output_1_loss: 13.5575 - output_2_loss: 13.1969 - val_loss: 41.7757 - val_output_0_loss: 14.3035 - val_output_1_loss: 13.8278 - val_output_2_loss: 13.6445\n",
      "Epoch 127/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 41.2355 - output_0_loss: 14.4991 - output_1_loss: 13.5452 - output_2_loss: 13.1912\n",
      "Epoch 00127: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.43, 25%:  0.96, 50%:  1.44, 75%:  2.01, 95%:  4.92, 100%: 43.10) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 67s 803ms/step - loss: 41.1830 - output_0_loss: 14.4813 - output_1_loss: 13.5275 - output_2_loss: 13.1742 - val_loss: 39.7396 - val_output_0_loss: 13.7011 - val_output_1_loss: 13.1129 - val_output_2_loss: 12.9256\n",
      "Epoch 128/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.7935 - output_0_loss: 14.3471 - output_1_loss: 13.4024 - output_2_loss: 13.0440  ETA: 35s - loss: 41.\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.89 (0%:  0.04, 5%:  0.39, 25%:  0.88, 50%:  1.35, 75%:  1.93, 95%:  4.82, 100%: 43.24) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.68, 50%:  0.76, 75%:  0.86, 95%:  0.94, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 76s 909ms/step - loss: 40.7352 - output_0_loss: 14.3254 - output_1_loss: 13.3842 - output_2_loss: 13.0256 - val_loss: 38.7774 - val_output_0_loss: 13.4175 - val_output_1_loss: 12.7803 - val_output_2_loss: 12.5795\n",
      "Epoch 129/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.7206 - output_0_loss: 14.3607 - output_1_loss: 13.3666 - output_2_loss: 12.9933\n",
      "Epoch 00129: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.04, 5%:  0.43, 25%:  0.93, 50%:  1.38, 75%:  1.96, 95%:  4.87, 100%: 45.14) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 75s 892ms/step - loss: 40.7160 - output_0_loss: 14.3563 - output_1_loss: 13.3664 - output_2_loss: 12.9933 - val_loss: 39.4146 - val_output_0_loss: 13.6028 - val_output_1_loss: 13.0118 - val_output_2_loss: 12.7999\n",
      "Epoch 130/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.5609 - output_0_loss: 14.2837 - output_1_loss: 13.3230 - output_2_loss: 12.9542\n",
      "Epoch 00130: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.04, 5%:  0.44, 25%:  0.94, 50%:  1.41, 75%:  1.99, 95%:  4.86, 100%: 43.73) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 70s 835ms/step - loss: 40.5997 - output_0_loss: 14.2973 - output_1_loss: 13.3347 - output_2_loss: 12.9677 - val_loss: 39.5822 - val_output_0_loss: 13.6859 - val_output_1_loss: 13.0521 - val_output_2_loss: 12.8442\n",
      "Epoch 131/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.1238 - output_0_loss: 14.1278 - output_1_loss: 13.1822 - output_2_loss: 12.8139\n",
      "Epoch 00131: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.90 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.34, 75%:  1.91, 95%:  4.87, 100%: 44.85) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 813ms/step - loss: 40.1002 - output_0_loss: 14.1226 - output_1_loss: 13.1736 - output_2_loss: 12.8040 - val_loss: 38.1275 - val_output_0_loss: 13.1893 - val_output_1_loss: 12.5561 - val_output_2_loss: 12.3821\n",
      "Epoch 132/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.3156 - output_0_loss: 14.2083 - output_1_loss: 13.2314 - output_2_loss: 12.8759\n",
      "Epoch 00132: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.98 (0%:  0.04, 5%:  0.45, 25%:  0.96, 50%:  1.44, 75%:  2.00, 95%:  4.92, 100%: 45.15) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 807ms/step - loss: 40.2215 - output_0_loss: 14.1754 - output_1_loss: 13.2004 - output_2_loss: 12.8456 - val_loss: 39.9121 - val_output_0_loss: 13.7522 - val_output_1_loss: 13.1673 - val_output_2_loss: 12.9925\n",
      "Epoch 133/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.8914 - output_0_loss: 14.0608 - output_1_loss: 13.0984 - output_2_loss: 12.7322\n",
      "Epoch 00133: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.36, 75%:  1.93, 95%:  4.80, 100%: 44.17) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 69s 820ms/step - loss: 39.9961 - output_0_loss: 14.1003 - output_1_loss: 13.1313 - output_2_loss: 12.7645 - val_loss: 38.5543 - val_output_0_loss: 13.3143 - val_output_1_loss: 12.7114 - val_output_2_loss: 12.5286\n",
      "Epoch 134/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.0719 - output_0_loss: 14.0838 - output_1_loss: 13.1687 - output_2_loss: 12.8194\n",
      "Epoch 00134: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.04, 5%:  0.43, 25%:  0.93, 50%:  1.39, 75%:  1.97, 95%:  4.87, 100%: 44.28) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 858ms/step - loss: 40.0311 - output_0_loss: 14.0707 - output_1_loss: 13.1552 - output_2_loss: 12.8052 - val_loss: 39.3016 - val_output_0_loss: 13.5614 - val_output_1_loss: 12.9731 - val_output_2_loss: 12.7671\n",
      "Epoch 135/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.0558 - output_0_loss: 14.1148 - output_1_loss: 13.1561 - output_2_loss: 12.7849\n",
      "Epoch 00135: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.04, 5%:  0.41, 25%:  0.91, 50%:  1.37, 75%:  1.96, 95%:  4.87, 100%: 44.61) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 867ms/step - loss: 39.9842 - output_0_loss: 14.0912 - output_1_loss: 13.1323 - output_2_loss: 12.7608 - val_loss: 38.9368 - val_output_0_loss: 13.4485 - val_output_1_loss: 12.8531 - val_output_2_loss: 12.6352\n",
      "Epoch 136/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.8327 - output_0_loss: 14.0146 - output_1_loss: 13.0794 - output_2_loss: 12.7387\n",
      "Epoch 00136: val_loss did not improve from 37.80336\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.42, 25%:  0.91, 50%:  1.38, 75%:  1.94, 95%:  4.83, 100%: 44.29) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 74s 882ms/step - loss: 39.8899 - output_0_loss: 14.0376 - output_1_loss: 13.0968 - output_2_loss: 12.7555 - val_loss: 38.5845 - val_output_0_loss: 13.3391 - val_output_1_loss: 12.7359 - val_output_2_loss: 12.5095\n",
      "Epoch 137/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.6947 - output_0_loss: 14.0130 - output_1_loss: 13.0276 - output_2_loss: 12.6541\n",
      "Epoch 00137: val_loss improved from 37.80336 to 37.67852, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.89 (0%:  0.00, 5%:  0.38, 25%:  0.87, 50%:  1.33, 75%:  1.90, 95%:  4.76, 100%: 44.64) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 74s 875ms/step - loss: 39.6041 - output_0_loss: 13.9821 - output_1_loss: 12.9976 - output_2_loss: 12.6244 - val_loss: 37.6785 - val_output_0_loss: 13.0435 - val_output_1_loss: 12.4245 - val_output_2_loss: 12.2105\n",
      "Epoch 138/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.7697 - output_0_loss: 14.0155 - output_1_loss: 13.0584 - output_2_loss: 12.6958\n",
      "Epoch 00138: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.89 (0%:  0.04, 5%:  0.39, 25%:  0.88, 50%:  1.33, 75%:  1.90, 95%:  4.81, 100%: 44.03) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 875ms/step - loss: 39.8062 - output_0_loss: 14.0279 - output_1_loss: 13.0707 - output_2_loss: 12.7076 - val_loss: 37.7056 - val_output_0_loss: 13.0670 - val_output_1_loss: 12.4260 - val_output_2_loss: 12.2126\n",
      "Epoch 139/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.9622 - output_0_loss: 14.0750 - output_1_loss: 13.1316 - output_2_loss: 12.7556\n",
      "Epoch 00139: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.06, 5%:  0.42, 25%:  0.93, 50%:  1.41, 75%:  1.98, 95%:  4.80, 100%: 44.12) \n",
      "confidence - mean:  0.76 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.94, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 865ms/step - loss: 39.9730 - output_0_loss: 14.0795 - output_1_loss: 13.1352 - output_2_loss: 12.7582 - val_loss: 38.9179 - val_output_0_loss: 13.4605 - val_output_1_loss: 12.8243 - val_output_2_loss: 12.6331\n",
      "Epoch 140/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.0909 - output_0_loss: 14.1297 - output_1_loss: 13.1628 - output_2_loss: 12.7985  ETA: 36s - lo\n",
      "Epoch 00140: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.00, 5%:  0.41, 25%:  0.93, 50%:  1.39, 75%:  1.97, 95%:  4.90, 100%: 44.37) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 73s 869ms/step - loss: 40.0201 - output_0_loss: 14.1057 - output_1_loss: 13.1391 - output_2_loss: 12.7752 - val_loss: 39.1442 - val_output_0_loss: 13.4858 - val_output_1_loss: 12.9110 - val_output_2_loss: 12.7474\n",
      "Epoch 141/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.9366 - output_0_loss: 14.0841 - output_1_loss: 13.1102 - output_2_loss: 12.7424\n",
      "Epoch 00141: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.98 (0%:  0.00, 5%:  0.43, 25%:  0.96, 50%:  1.42, 75%:  2.00, 95%:  4.91, 100%: 43.99) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 71s 843ms/step - loss: 39.8191 - output_0_loss: 14.0415 - output_1_loss: 13.0720 - output_2_loss: 12.7057 - val_loss: 39.7658 - val_output_0_loss: 13.7065 - val_output_1_loss: 13.1026 - val_output_2_loss: 12.9567\n",
      "Epoch 142/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.9882 - output_0_loss: 14.0856 - output_1_loss: 13.1292 - output_2_loss: 12.7734\n",
      "Epoch 00142: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.04, 5%:  0.40, 25%:  0.89, 50%:  1.36, 75%:  1.92, 95%:  4.84, 100%: 44.33) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 837ms/step - loss: 39.8991 - output_0_loss: 14.0526 - output_1_loss: 13.1006 - output_2_loss: 12.7459 - val_loss: 38.6174 - val_output_0_loss: 13.3355 - val_output_1_loss: 12.7388 - val_output_2_loss: 12.5431\n",
      "Epoch 143/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.4997 - output_0_loss: 13.9387 - output_1_loss: 12.9689 - output_2_loss: 12.5921  ETA: 37s - loss: 39.5192 - output_0_loss: 13.9888 - o - ETA: 21s - loss: 39.5456 - output_0_loss: 13.9930 - out\n",
      "Epoch 00143: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.04, 5%:  0.43, 25%:  0.93, 50%:  1.41, 75%:  1.98, 95%:  4.90, 100%: 43.77) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.76, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 71s 847ms/step - loss: 39.4411 - output_0_loss: 13.9229 - output_1_loss: 12.9480 - output_2_loss: 12.5702 - val_loss: 39.1718 - val_output_0_loss: 13.5409 - val_output_1_loss: 12.9216 - val_output_2_loss: 12.7094\n",
      "Epoch 144/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.3575 - output_0_loss: 14.2178 - output_1_loss: 13.2477 - output_2_loss: 12.8919\n",
      "Epoch 00144: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.04, 5%:  0.41, 25%:  0.90, 50%:  1.36, 75%:  1.94, 95%:  4.93, 100%: 43.89) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 857ms/step - loss: 40.3782 - output_0_loss: 14.2225 - output_1_loss: 13.2553 - output_2_loss: 12.9004 - val_loss: 38.6160 - val_output_0_loss: 13.3103 - val_output_1_loss: 12.7437 - val_output_2_loss: 12.5620\n",
      "Epoch 145/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.8494 - output_0_loss: 14.0835 - output_1_loss: 13.0777 - output_2_loss: 12.6882\n",
      "Epoch 00145: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.90 (0%:  0.04, 5%:  0.40, 25%:  0.89, 50%:  1.35, 75%:  1.92, 95%:  4.82, 100%: 44.17) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 842ms/step - loss: 39.7723 - output_0_loss: 14.0539 - output_1_loss: 13.0530 - output_2_loss: 12.6654 - val_loss: 38.3684 - val_output_0_loss: 13.2374 - val_output_1_loss: 12.6613 - val_output_2_loss: 12.4697\n",
      "Epoch 146/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.8017 - output_0_loss: 14.0334 - output_1_loss: 13.0644 - output_2_loss: 12.7039\n",
      "Epoch 00146: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.00, 5%:  0.43, 25%:  0.93, 50%:  1.40, 75%:  1.96, 95%:  4.87, 100%: 43.52) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 72s 863ms/step - loss: 39.8218 - output_0_loss: 14.0392 - output_1_loss: 13.0714 - output_2_loss: 12.7112 - val_loss: 39.0831 - val_output_0_loss: 13.4546 - val_output_1_loss: 12.8981 - val_output_2_loss: 12.7303\n",
      "Epoch 147/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.5163 - output_0_loss: 13.9218 - output_1_loss: 12.9753 - output_2_loss: 12.6193  ETA: 17s - loss: 42.0143 - output_0_loss: 14.7487 - output_1_\n",
      "Epoch 00147: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.99 (0%:  0.00, 5%:  0.46, 25%:  0.97, 50%:  1.46, 75%:  2.04, 95%:  4.92, 100%: 44.29) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 39.6339 - output_0_loss: 13.9642 - output_1_loss: 13.0122 - output_2_loss: 12.6574 - val_loss: 40.3793 - val_output_0_loss: 13.8889 - val_output_1_loss: 13.3557 - val_output_2_loss: 13.1347\n",
      "Epoch 148/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.6263 - output_0_loss: 13.9828 - output_1_loss: 13.0118 - output_2_loss: 12.6316\n",
      "Epoch 00148: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.43, 25%:  0.94, 50%:  1.41, 75%:  2.00, 95%:  4.84, 100%: 44.24) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 77s 913ms/step - loss: 39.4881 - output_0_loss: 13.9331 - output_1_loss: 12.9673 - output_2_loss: 12.5877 - val_loss: 39.2106 - val_output_0_loss: 13.5167 - val_output_1_loss: 12.9322 - val_output_2_loss: 12.7617\n",
      "Epoch 149/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.5370 - output_0_loss: 13.9495 - output_1_loss: 12.9826 - output_2_loss: 12.6049\n",
      "Epoch 00149: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.36, 75%:  1.94, 95%:  4.84, 100%: 43.69) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 69s 821ms/step - loss: 39.4885 - output_0_loss: 13.9343 - output_1_loss: 12.9663 - output_2_loss: 12.5880 - val_loss: 38.4053 - val_output_0_loss: 13.2581 - val_output_1_loss: 12.6722 - val_output_2_loss: 12.4750\n",
      "Epoch 150/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.7261 - output_0_loss: 13.9808 - output_1_loss: 13.0462 - output_2_loss: 12.6991\n",
      "Epoch 00150: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.35, 75%:  1.92, 95%:  4.86, 100%: 43.73) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 69s 818ms/step - loss: 39.8215 - output_0_loss: 14.0141 - output_1_loss: 13.0767 - output_2_loss: 12.7306 - val_loss: 38.5161 - val_output_0_loss: 13.2713 - val_output_1_loss: 12.7077 - val_output_2_loss: 12.5372\n",
      "Epoch 151/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.5107 - output_0_loss: 13.9342 - output_1_loss: 12.9701 - output_2_loss: 12.6064\n",
      "Epoch 00151: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.88, 50%:  1.35, 75%:  1.92, 95%:  4.79, 100%: 43.85) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 73s 868ms/step - loss: 39.5120 - output_0_loss: 13.9313 - output_1_loss: 12.9717 - output_2_loss: 12.6090 - val_loss: 38.2275 - val_output_0_loss: 13.1658 - val_output_1_loss: 12.6236 - val_output_2_loss: 12.4381\n",
      "Epoch 152/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.2516 - output_0_loss: 13.8476 - output_1_loss: 12.8813 - output_2_loss: 12.5227\n",
      "Epoch 00152: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.04, 5%:  0.43, 25%:  0.95, 50%:  1.42, 75%:  2.00, 95%:  4.88, 100%: 43.63) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 862ms/step - loss: 39.2468 - output_0_loss: 13.8451 - output_1_loss: 12.8793 - output_2_loss: 12.5224 - val_loss: 39.3235 - val_output_0_loss: 13.5158 - val_output_1_loss: 12.9764 - val_output_2_loss: 12.8313\n",
      "Epoch 153/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.4738 - output_0_loss: 13.9341 - output_1_loss: 12.9494 - output_2_loss: 12.5903  ETA: 36s - lo\n",
      "Epoch 00153: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.37, 75%:  1.94, 95%:  4.85, 100%: 44.02) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 845ms/step - loss: 39.5221 - output_0_loss: 13.9486 - output_1_loss: 12.9665 - output_2_loss: 12.6071 - val_loss: 39.0226 - val_output_0_loss: 13.4445 - val_output_1_loss: 12.8754 - val_output_2_loss: 12.7026\n",
      "Epoch 154/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3436 - output_0_loss: 13.8877 - output_1_loss: 12.9112 - output_2_loss: 12.5447\n",
      "Epoch 00154: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.42, 25%:  0.93, 50%:  1.38, 75%:  1.96, 95%:  4.87, 100%: 43.59) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 69s 818ms/step - loss: 39.2512 - output_0_loss: 13.8540 - output_1_loss: 12.8804 - output_2_loss: 12.5168 - val_loss: 38.8751 - val_output_0_loss: 13.4204 - val_output_1_loss: 12.8253 - val_output_2_loss: 12.6294\n",
      "Epoch 155/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3740 - output_0_loss: 13.8711 - output_1_loss: 12.9355 - output_2_loss: 12.5674\n",
      "Epoch 00155: val_loss did not improve from 37.67852\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.02, 5%:  0.43, 25%:  0.93, 50%:  1.39, 75%:  1.97, 95%:  4.84, 100%: 43.61) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 841ms/step - loss: 39.4389 - output_0_loss: 13.8919 - output_1_loss: 12.9567 - output_2_loss: 12.5904 - val_loss: 39.1110 - val_output_0_loss: 13.4774 - val_output_1_loss: 12.8928 - val_output_2_loss: 12.7408\n",
      "Epoch 156/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.6723 - output_0_loss: 13.9818 - output_1_loss: 13.0234 - output_2_loss: 12.6671\n",
      "Epoch 00156: val_loss improved from 37.67852 to 37.58626, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.88 (0%:  0.00, 5%:  0.40, 25%:  0.88, 50%:  1.33, 75%:  1.90, 95%:  4.78, 100%: 43.58) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 70s 836ms/step - loss: 39.6413 - output_0_loss: 13.9711 - output_1_loss: 13.0137 - output_2_loss: 12.6566 - val_loss: 37.5863 - val_output_0_loss: 13.0275 - val_output_1_loss: 12.3858 - val_output_2_loss: 12.1730\n",
      "Epoch 157/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.8134 - output_0_loss: 14.0247 - output_1_loss: 13.0775 - output_2_loss: 12.7112\n",
      "Epoch 00157: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.90 (0%:  0.00, 5%:  0.39, 25%:  0.89, 50%:  1.35, 75%:  1.92, 95%:  4.72, 100%: 43.66) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 69s 820ms/step - loss: 39.8662 - output_0_loss: 14.0456 - output_1_loss: 13.0937 - output_2_loss: 12.7269 - val_loss: 37.9103 - val_output_0_loss: 13.1068 - val_output_1_loss: 12.4895 - val_output_2_loss: 12.3140\n",
      "Epoch 158/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3663 - output_0_loss: 13.8899 - output_1_loss: 12.9216 - output_2_loss: 12.5547\n",
      "Epoch 00158: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.42, 25%:  0.91, 50%:  1.38, 75%:  1.95, 95%:  4.90, 100%: 43.52) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.87, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 75s 888ms/step - loss: 39.2811 - output_0_loss: 13.8589 - output_1_loss: 12.8938 - output_2_loss: 12.5284 - val_loss: 38.8863 - val_output_0_loss: 13.3912 - val_output_1_loss: 12.8285 - val_output_2_loss: 12.6666\n",
      "Epoch 159/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.1648 - output_0_loss: 14.1670 - output_1_loss: 13.1862 - output_2_loss: 12.8117\n",
      "Epoch 00159: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.89 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.35, 75%:  1.93, 95%:  4.80, 100%: 43.45) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 859ms/step - loss: 40.2259 - output_0_loss: 14.1849 - output_1_loss: 13.2070 - output_2_loss: 12.8340 - val_loss: 38.3952 - val_output_0_loss: 13.2915 - val_output_1_loss: 12.6597 - val_output_2_loss: 12.4440\n",
      "Epoch 160/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.5801 - output_0_loss: 13.9359 - output_1_loss: 13.0055 - output_2_loss: 12.6386  ETA: 27s - loss: 39.1434 - output_0_los\n",
      "Epoch 00160: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.42, 25%:  0.91, 50%:  1.37, 75%:  1.93, 95%:  4.86, 100%: 43.51) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.04) \n",
      "\n",
      "84/84 [==============================] - 72s 862ms/step - loss: 39.5669 - output_0_loss: 13.9299 - output_1_loss: 13.0023 - output_2_loss: 12.6347 - val_loss: 38.7584 - val_output_0_loss: 13.3882 - val_output_1_loss: 12.7701 - val_output_2_loss: 12.6002\n",
      "Epoch 161/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.4130 - output_0_loss: 13.9102 - output_1_loss: 12.9406 - output_2_loss: 12.5621\n",
      "Epoch 00161: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.04, 5%:  0.41, 25%:  0.92, 50%:  1.37, 75%:  1.94, 95%:  4.76, 100%: 44.32) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 72s 851ms/step - loss: 39.3701 - output_0_loss: 13.8932 - output_1_loss: 12.9264 - output_2_loss: 12.5506 - val_loss: 38.7003 - val_output_0_loss: 13.3292 - val_output_1_loss: 12.7684 - val_output_2_loss: 12.6027\n",
      "Epoch 162/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.9837 - output_0_loss: 13.7694 - output_1_loss: 12.7968 - output_2_loss: 12.4175\n",
      "Epoch 00162: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.45, 25%:  0.95, 50%:  1.42, 75%:  2.00, 95%:  4.90, 100%: 43.62) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 67s 802ms/step - loss: 39.0214 - output_0_loss: 13.7776 - output_1_loss: 12.8100 - output_2_loss: 12.4338 - val_loss: 39.5917 - val_output_0_loss: 13.6098 - val_output_1_loss: 13.0621 - val_output_2_loss: 12.9198\n",
      "Epoch 163/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.4041 - output_0_loss: 13.8932 - output_1_loss: 12.9333 - output_2_loss: 12.5776\n",
      "Epoch 00163: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.45, 25%:  0.95, 50%:  1.41, 75%:  2.00, 95%:  4.89, 100%: 43.62) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.01) \n",
      "\n",
      "84/84 [==============================] - 72s 861ms/step - loss: 39.4280 - output_0_loss: 13.8993 - output_1_loss: 12.9423 - output_2_loss: 12.5863 - val_loss: 39.2333 - val_output_0_loss: 13.5251 - val_output_1_loss: 12.9528 - val_output_2_loss: 12.7554\n",
      "Epoch 164/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.8920 - output_0_loss: 13.7352 - output_1_loss: 12.7653 - output_2_loss: 12.3915\n",
      "Epoch 00164: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.04, 5%:  0.43, 25%:  0.92, 50%:  1.39, 75%:  1.96, 95%:  4.87, 100%: 43.87) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.87, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 67s 804ms/step - loss: 38.9608 - output_0_loss: 13.7571 - output_1_loss: 12.7881 - output_2_loss: 12.4157 - val_loss: 38.4824 - val_output_0_loss: 13.2705 - val_output_1_loss: 12.6946 - val_output_2_loss: 12.5173\n",
      "Epoch 165/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.1891 - output_0_loss: 13.8395 - output_1_loss: 12.8570 - output_2_loss: 12.4926  ETA: 10s - loss: 39.3138 - output_0_loss: 13.8824 - output_1_loss: 12.9006 - output_2\n",
      "Epoch 00165: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.04, 5%:  0.42, 25%:  0.95, 50%:  1.42, 75%:  2.01, 95%:  4.94, 100%: 43.74) \n",
      "confidence - mean:  0.77 (0%:  0.03, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.87, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 72s 859ms/step - loss: 39.1156 - output_0_loss: 13.8132 - output_1_loss: 12.8335 - output_2_loss: 12.4688 - val_loss: 39.3195 - val_output_0_loss: 13.5370 - val_output_1_loss: 12.9663 - val_output_2_loss: 12.8162\n",
      "Epoch 166/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.0195 - output_0_loss: 14.1123 - output_1_loss: 13.1449 - output_2_loss: 12.7623\n",
      "Epoch 00166: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.36, 75%:  1.94, 95%:  4.75, 100%: 43.73) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 74s 880ms/step - loss: 40.0689 - output_0_loss: 14.1263 - output_1_loss: 13.1618 - output_2_loss: 12.7808 - val_loss: 38.3142 - val_output_0_loss: 13.2058 - val_output_1_loss: 12.6342 - val_output_2_loss: 12.4743\n",
      "Epoch 167/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.6684 - output_0_loss: 13.9909 - output_1_loss: 13.0255 - output_2_loss: 12.6521\n",
      "Epoch 00167: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.43, 25%:  0.93, 50%:  1.40, 75%:  1.98, 95%:  4.85, 100%: 44.42) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 68s 804ms/step - loss: 39.6512 - output_0_loss: 13.9853 - output_1_loss: 13.0201 - output_2_loss: 12.6458 - val_loss: 39.1947 - val_output_0_loss: 13.4743 - val_output_1_loss: 12.9416 - val_output_2_loss: 12.7787\n",
      "Epoch 168/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.5619 - output_0_loss: 13.9533 - output_1_loss: 12.9884 - output_2_loss: 12.6202- ETA: 6s - loss: 39.3109 - output_0_loss: 13.8564 - output_1_loss: 12.9078 - output_2_loss:\n",
      "Epoch 00168: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.97 (0%:  0.00, 5%:  0.43, 25%:  0.95, 50%:  1.42, 75%:  2.00, 95%:  4.99, 100%: 44.17) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 75s 897ms/step - loss: 39.4516 - output_0_loss: 13.9171 - output_1_loss: 12.9510 - output_2_loss: 12.5836 - val_loss: 39.7252 - val_output_0_loss: 13.6574 - val_output_1_loss: 13.1087 - val_output_2_loss: 12.9592\n",
      "Epoch 169/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.0614 - output_0_loss: 13.7844 - output_1_loss: 12.8274 - output_2_loss: 12.4496\n",
      "Epoch 00169: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.99 (0%:  0.00, 5%:  0.44, 25%:  0.97, 50%:  1.44, 75%:  2.04, 95%:  4.89, 100%: 43.67) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 76s 902ms/step - loss: 39.0377 - output_0_loss: 13.7755 - output_1_loss: 12.8199 - output_2_loss: 12.4422 - val_loss: 40.1383 - val_output_0_loss: 13.7913 - val_output_1_loss: 13.2616 - val_output_2_loss: 13.0854\n",
      "Epoch 170/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.2536 - output_0_loss: 13.8581 - output_1_loss: 12.8792 - output_2_loss: 12.5163\n",
      "Epoch 00170: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.90, 50%:  1.36, 75%:  1.93, 95%:  4.79, 100%: 43.40) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 70s 828ms/step - loss: 39.3131 - output_0_loss: 13.8778 - output_1_loss: 12.8992 - output_2_loss: 12.5361 - val_loss: 38.1844 - val_output_0_loss: 13.1616 - val_output_1_loss: 12.5876 - val_output_2_loss: 12.4351\n",
      "Epoch 171/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.2785 - output_0_loss: 13.8655 - output_1_loss: 12.8913 - output_2_loss: 12.5216\n",
      "Epoch 00171: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.37, 75%:  1.95, 95%:  4.77, 100%: 43.75) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 850ms/step - loss: 39.2685 - output_0_loss: 13.8603 - output_1_loss: 12.8887 - output_2_loss: 12.5195 - val_loss: 38.9592 - val_output_0_loss: 13.4557 - val_output_1_loss: 12.8589 - val_output_2_loss: 12.6446\n",
      "Epoch 172/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3614 - output_0_loss: 13.9038 - output_1_loss: 12.9160 - output_2_loss: 12.5415\n",
      "Epoch 00172: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.00, 5%:  0.42, 25%:  0.93, 50%:  1.40, 75%:  1.99, 95%:  4.97, 100%: 44.26) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 67s 803ms/step - loss: 39.3181 - output_0_loss: 13.8896 - output_1_loss: 12.9012 - output_2_loss: 12.5273 - val_loss: 39.7766 - val_output_0_loss: 13.6360 - val_output_1_loss: 13.1619 - val_output_2_loss: 12.9786\n",
      "Epoch 173/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.9955 - output_0_loss: 13.7679 - output_1_loss: 12.8009 - output_2_loss: 12.4267\n",
      "Epoch 00173: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.00, 5%:  0.42, 25%:  0.91, 50%:  1.37, 75%:  1.95, 95%:  4.91, 100%: 51.07) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 39.0285 - output_0_loss: 13.7803 - output_1_loss: 12.8111 - output_2_loss: 12.4371 - val_loss: 39.0764 - val_output_0_loss: 13.4395 - val_output_1_loss: 12.9004 - val_output_2_loss: 12.7365\n",
      "Epoch 174/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.2505 - output_0_loss: 13.8460 - output_1_loss: 12.8835 - output_2_loss: 12.5210\n",
      "Epoch 00174: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.04, 5%:  0.40, 25%:  0.90, 50%:  1.36, 75%:  1.93, 95%:  4.86, 100%: 43.68) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 72s 853ms/step - loss: 39.2099 - output_0_loss: 13.8321 - output_1_loss: 12.8702 - output_2_loss: 12.5076 - val_loss: 38.5342 - val_output_0_loss: 13.2346 - val_output_1_loss: 12.7211 - val_output_2_loss: 12.5785\n",
      "Epoch 175/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.8316 - output_0_loss: 13.7391 - output_1_loss: 12.7387 - output_2_loss: 12.3538\n",
      "Epoch 00175: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.91 (0%:  0.00, 5%:  0.40, 25%:  0.88, 50%:  1.36, 75%:  1.93, 95%:  4.93, 100%: 43.75) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 831ms/step - loss: 38.8825 - output_0_loss: 13.7522 - output_1_loss: 12.7564 - output_2_loss: 12.3739 - val_loss: 38.4852 - val_output_0_loss: 13.2019 - val_output_1_loss: 12.6961 - val_output_2_loss: 12.5873\n",
      "Epoch 176/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 40.4396 - output_0_loss: 14.2445 - output_1_loss: 13.2797 - output_2_loss: 12.9154\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.36, 75%:  1.93, 95%:  4.82, 100%: 43.55) \n",
      "confidence - mean:  0.76 (0%:  0.02, 5%:  0.55, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 76s 911ms/step - loss: 40.3860 - output_0_loss: 14.2270 - output_1_loss: 13.2618 - output_2_loss: 12.8972 - val_loss: 38.9724 - val_output_0_loss: 13.3677 - val_output_1_loss: 12.8714 - val_output_2_loss: 12.7333\n",
      "Epoch 177/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3925 - output_0_loss: 13.8886 - output_1_loss: 12.9275 - output_2_loss: 12.5764\n",
      "Epoch 00177: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.40, 25%:  0.89, 50%:  1.36, 75%:  1.93, 95%:  4.89, 100%: 43.52) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 69s 824ms/step - loss: 39.3348 - output_0_loss: 13.8694 - output_1_loss: 12.9090 - output_2_loss: 12.5564 - val_loss: 38.7620 - val_output_0_loss: 13.3129 - val_output_1_loss: 12.8108 - val_output_2_loss: 12.6382\n",
      "Epoch 178/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.7967 - output_0_loss: 13.7105 - output_1_loss: 12.7261 - output_2_loss: 12.3601\n",
      "Epoch 00178: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.04, 5%:  0.41, 25%:  0.90, 50%:  1.37, 75%:  1.95, 95%:  4.87, 100%: 43.77) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 68s 815ms/step - loss: 38.7327 - output_0_loss: 13.6880 - output_1_loss: 12.7057 - output_2_loss: 12.3390 - val_loss: 38.7106 - val_output_0_loss: 13.3013 - val_output_1_loss: 12.7888 - val_output_2_loss: 12.6205\n",
      "Epoch 179/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.1562 - output_0_loss: 13.8235 - output_1_loss: 12.8536 - output_2_loss: 12.4791\n",
      "Epoch 00179: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.43, 25%:  0.91, 50%:  1.38, 75%:  1.97, 95%:  4.89, 100%: 43.83) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 839ms/step - loss: 39.1525 - output_0_loss: 13.8231 - output_1_loss: 12.8524 - output_2_loss: 12.4769 - val_loss: 39.2005 - val_output_0_loss: 13.4555 - val_output_1_loss: 12.9496 - val_output_2_loss: 12.7954\n",
      "Epoch 180/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.6417 - output_0_loss: 13.6576 - output_1_loss: 12.6787 - output_2_loss: 12.3055\n",
      "Epoch 00180: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.00, 5%:  0.43, 25%:  0.92, 50%:  1.39, 75%:  1.98, 95%:  4.85, 100%: 43.77) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 830ms/step - loss: 38.6221 - output_0_loss: 13.6527 - output_1_loss: 12.6718 - output_2_loss: 12.2976 - val_loss: 39.1377 - val_output_0_loss: 13.4390 - val_output_1_loss: 12.9259 - val_output_2_loss: 12.7728\n",
      "Epoch 181/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.5240 - output_0_loss: 13.6133 - output_1_loss: 12.6431 - output_2_loss: 12.2675\n",
      "Epoch 00181: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.00, 5%:  0.43, 25%:  0.92, 50%:  1.39, 75%:  1.97, 95%:  4.85, 100%: 44.07) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 75s 889ms/step - loss: 38.5687 - output_0_loss: 13.6276 - output_1_loss: 12.6585 - output_2_loss: 12.2826 - val_loss: 39.1111 - val_output_0_loss: 13.4279 - val_output_1_loss: 12.9126 - val_output_2_loss: 12.7706\n",
      "Epoch 182/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.9499 - output_0_loss: 13.7451 - output_1_loss: 12.7881 - output_2_loss: 12.4167 \n",
      "Epoch 00182: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.04, 5%:  0.41, 25%:  0.91, 50%:  1.38, 75%:  1.96, 95%:  4.91, 100%: 44.01) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 71s 842ms/step - loss: 38.9693 - output_0_loss: 13.7539 - output_1_loss: 12.7945 - output_2_loss: 12.4208 - val_loss: 38.9300 - val_output_0_loss: 13.3827 - val_output_1_loss: 12.8501 - val_output_2_loss: 12.6971\n",
      "Epoch 183/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.8372 - output_0_loss: 13.7433 - output_1_loss: 12.7378 - output_2_loss: 12.3561- ETA: 9s - loss: 38.6544 - output_0_loss: 13.6560 - output_1_loss: 12.6872 - output_2_l\n",
      "Epoch 00183: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.96 (0%:  0.04, 5%:  0.43, 25%:  0.93, 50%:  1.40, 75%:  1.98, 95%:  4.90, 100%: 43.89) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 814ms/step - loss: 38.8850 - output_0_loss: 13.7586 - output_1_loss: 12.7534 - output_2_loss: 12.3730 - val_loss: 39.3495 - val_output_0_loss: 13.5087 - val_output_1_loss: 12.9924 - val_output_2_loss: 12.8484\n",
      "Epoch 184/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.9343 - output_0_loss: 13.7651 - output_1_loss: 12.7785 - output_2_loss: 12.3907\n",
      "Epoch 00184: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.98 (0%:  0.04, 5%:  0.43, 25%:  0.95, 50%:  1.42, 75%:  2.00, 95%:  4.90, 100%: 44.13) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 74s 884ms/step - loss: 39.0484 - output_0_loss: 13.7997 - output_1_loss: 12.8169 - output_2_loss: 12.4318 - val_loss: 39.7309 - val_output_0_loss: 13.6321 - val_output_1_loss: 13.1251 - val_output_2_loss: 12.9736\n",
      "Epoch 185/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.7313 - output_0_loss: 13.7192 - output_1_loss: 12.7014 - output_2_loss: 12.3106\n",
      "Epoch 00185: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.95 (0%:  0.04, 5%:  0.42, 25%:  0.92, 50%:  1.39, 75%:  1.97, 95%:  4.88, 100%: 44.21) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 66s 791ms/step - loss: 38.7186 - output_0_loss: 13.7105 - output_1_loss: 12.6985 - output_2_loss: 12.3096 - val_loss: 38.9756 - val_output_0_loss: 13.4015 - val_output_1_loss: 12.8694 - val_output_2_loss: 12.7047\n",
      "Epoch 186/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.5371 - output_0_loss: 13.9327 - output_1_loss: 12.9919 - output_2_loss: 12.6125\n",
      "Epoch 00186: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.04, 5%:  0.40, 25%:  0.90, 50%:  1.36, 75%:  1.93, 95%:  4.86, 100%: 44.08) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 831ms/step - loss: 39.5493 - output_0_loss: 13.9389 - output_1_loss: 12.9954 - output_2_loss: 12.6149 - val_loss: 38.5227 - val_output_0_loss: 13.2603 - val_output_1_loss: 12.7167 - val_output_2_loss: 12.5458\n",
      "Epoch 187/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.2634 - output_0_loss: 13.8643 - output_1_loss: 12.8835 - output_2_loss: 12.5157\n",
      "Epoch 00187: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.04, 5%:  0.41, 25%:  0.91, 50%:  1.36, 75%:  1.93, 95%:  4.88, 100%: 44.08) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 76s 910ms/step - loss: 39.3590 - output_0_loss: 13.8911 - output_1_loss: 12.9170 - output_2_loss: 12.5508 - val_loss: 38.5993 - val_output_0_loss: 13.2881 - val_output_1_loss: 12.7431 - val_output_2_loss: 12.5681\n",
      "Epoch 188/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.1822 - output_0_loss: 13.8515 - output_1_loss: 12.8583 - output_2_loss: 12.4724  ETA: 11s - loss: 39.2345 - output_0_loss: 13.8667 - output_1_loss: 12.8814 - out\n",
      "Epoch 00188: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.41, 25%:  0.90, 50%:  1.36, 75%:  1.93, 95%:  4.82, 100%: 44.21) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 809ms/step - loss: 39.2265 - output_0_loss: 13.8645 - output_1_loss: 12.8736 - output_2_loss: 12.4884 - val_loss: 38.6399 - val_output_0_loss: 13.2934 - val_output_1_loss: 12.7510 - val_output_2_loss: 12.5955\n",
      "Epoch 189/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3122 - output_0_loss: 13.9044 - output_1_loss: 12.8943 - output_2_loss: 12.5136  ETA: 12s - loss: 39.5919 - output_0_loss: 14.0087 - output_1_loss: 12.9851 - ou\n",
      "Epoch 00189: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.37, 75%:  1.94, 95%:  4.82, 100%: 44.08) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 73s 875ms/step - loss: 39.3157 - output_0_loss: 13.9059 - output_1_loss: 12.8959 - output_2_loss: 12.5139 - val_loss: 38.7844 - val_output_0_loss: 13.3412 - val_output_1_loss: 12.8022 - val_output_2_loss: 12.6410\n",
      "Epoch 190/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.8246 - output_0_loss: 13.7217 - output_1_loss: 12.7371 - output_2_loss: 12.3658\n",
      "Epoch 00190: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.04, 5%:  0.42, 25%:  0.90, 50%:  1.37, 75%:  1.94, 95%:  4.88, 100%: 44.02) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 72s 858ms/step - loss: 38.7955 - output_0_loss: 13.7123 - output_1_loss: 12.7280 - output_2_loss: 12.3552 - val_loss: 38.7464 - val_output_0_loss: 13.3213 - val_output_1_loss: 12.7869 - val_output_2_loss: 12.6382\n",
      "Epoch 191/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.3706 - output_0_loss: 13.8956 - output_1_loss: 12.9215 - output_2_loss: 12.5535\n",
      "Epoch 00191: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.38, 75%:  1.95, 95%:  4.87, 100%: 44.15) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 68s 811ms/step - loss: 39.2926 - output_0_loss: 13.8716 - output_1_loss: 12.8954 - output_2_loss: 12.5256 - val_loss: 38.8529 - val_output_0_loss: 13.3656 - val_output_1_loss: 12.8242 - val_output_2_loss: 12.6632\n",
      "Epoch 192/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.1763 - output_0_loss: 13.8543 - output_1_loss: 12.8505 - output_2_loss: 12.4715\n",
      "Epoch 00192: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.40, 25%:  0.91, 50%:  1.37, 75%:  1.95, 95%:  4.88, 100%: 43.97) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 851ms/step - loss: 39.1891 - output_0_loss: 13.8575 - output_1_loss: 12.8551 - output_2_loss: 12.4765 - val_loss: 38.7804 - val_output_0_loss: 13.3321 - val_output_1_loss: 12.7977 - val_output_2_loss: 12.6506\n",
      "Epoch 193/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.6611 - output_0_loss: 13.9946 - output_1_loss: 13.0224 - output_2_loss: 12.6441  ETA: 23s - loss: 39.7898 - output_0_loss: 14\n",
      "Epoch 00193: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.41, 25%:  0.92, 50%:  1.39, 75%:  1.97, 95%:  4.87, 100%: 43.72) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 68s 810ms/step - loss: 39.6908 - output_0_loss: 14.0065 - output_1_loss: 13.0306 - output_2_loss: 12.6536 - val_loss: 39.0841 - val_output_0_loss: 13.4312 - val_output_1_loss: 12.8998 - val_output_2_loss: 12.7531\n",
      "Epoch 194/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.6443 - output_0_loss: 13.6530 - output_1_loss: 12.6831 - output_2_loss: 12.3081\n",
      "Epoch 00194: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.94 (0%:  0.00, 5%:  0.42, 25%:  0.92, 50%:  1.39, 75%:  1.96, 95%:  4.86, 100%: 43.78) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.03) \n",
      "\n",
      "84/84 [==============================] - 69s 819ms/step - loss: 38.6552 - output_0_loss: 13.6581 - output_1_loss: 12.6865 - output_2_loss: 12.3106 - val_loss: 38.8711 - val_output_0_loss: 13.3799 - val_output_1_loss: 12.8314 - val_output_2_loss: 12.6598\n",
      "Epoch 195/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.6352 - output_0_loss: 13.6542 - output_1_loss: 12.6822 - output_2_loss: 12.2987\n",
      "Epoch 00195: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.38, 75%:  1.94, 95%:  4.84, 100%: 43.84) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 850ms/step - loss: 38.7245 - output_0_loss: 13.6912 - output_1_loss: 12.7086 - output_2_loss: 12.3246 - val_loss: 38.6813 - val_output_0_loss: 13.3181 - val_output_1_loss: 12.7680 - val_output_2_loss: 12.5952\n",
      "Epoch 196/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.6688 - output_0_loss: 13.9973 - output_1_loss: 13.0345 - output_2_loss: 12.6370\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.41, 25%:  0.90, 50%:  1.37, 75%:  1.93, 95%:  4.84, 100%: 43.73) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 67s 796ms/step - loss: 39.6892 - output_0_loss: 14.0097 - output_1_loss: 13.0395 - output_2_loss: 12.6400 - val_loss: 38.5925 - val_output_0_loss: 13.2898 - val_output_1_loss: 12.7353 - val_output_2_loss: 12.5674\n",
      "Epoch 197/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 38.8221 - output_0_loss: 13.7091 - output_1_loss: 12.7506 - output_2_loss: 12.3624\n",
      "Epoch 00197: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.92 (0%:  0.00, 5%:  0.41, 25%:  0.90, 50%:  1.37, 75%:  1.93, 95%:  4.81, 100%: 43.73) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 71s 842ms/step - loss: 38.9175 - output_0_loss: 13.7434 - output_1_loss: 12.7833 - output_2_loss: 12.3908 - val_loss: 38.6122 - val_output_0_loss: 13.3000 - val_output_1_loss: 12.7436 - val_output_2_loss: 12.5686\n",
      "Epoch 198/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.1340 - output_0_loss: 13.8199 - output_1_loss: 12.8477 - output_2_loss: 12.4664\n",
      "Epoch 00198: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.37, 75%:  1.94, 95%:  4.84, 100%: 43.72) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 68s 811ms/step - loss: 39.1445 - output_0_loss: 13.8245 - output_1_loss: 12.8511 - output_2_loss: 12.4688 - val_loss: 38.6608 - val_output_0_loss: 13.3154 - val_output_1_loss: 12.7589 - val_output_2_loss: 12.5865\n",
      "Epoch 199/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.2634 - output_0_loss: 13.8865 - output_1_loss: 12.8837 - output_2_loss: 12.4931\n",
      "Epoch 00199: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.41, 25%:  0.91, 50%:  1.38, 75%:  1.94, 95%:  4.84, 100%: 43.78) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 70s 835ms/step - loss: 39.3389 - output_0_loss: 13.9108 - output_1_loss: 12.9094 - output_2_loss: 12.5187 - val_loss: 38.6989 - val_output_0_loss: 13.3278 - val_output_1_loss: 12.7716 - val_output_2_loss: 12.5995\n",
      "Epoch 200/200\n",
      "83/84 [============================>.] - ETA: 0s - loss: 39.1574 - output_0_loss: 13.8446 - output_1_loss: 12.8455 - output_2_loss: 12.4672\n",
      "Epoch 00200: val_loss did not improve from 37.58626\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  1.93 (0%:  0.00, 5%:  0.42, 25%:  0.91, 50%:  1.38, 75%:  1.94, 95%:  4.84, 100%: 43.78) \n",
      "confidence - mean:  0.77 (0%:  0.02, 5%:  0.56, 25%:  0.69, 50%:  0.77, 75%:  0.86, 95%:  0.95, 100%:  1.02) \n",
      "\n",
      "84/84 [==============================] - 76s 902ms/step - loss: 39.1700 - output_0_loss: 13.8448 - output_1_loss: 12.8510 - output_2_loss: 12.4741 - val_loss: 38.8157 - val_output_0_loss: 13.3639 - val_output_1_loss: 12.8105 - val_output_2_loss: 12.6413\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    batch_size=16,\n",
    "    validation_batch_size=10,\n",
    "    callbacks=callbacks,\n",
    "    #epochs=1000, # Increase the number of epochs to train the model longer\n",
    "    epochs=200,\n",
    "    n_workers=8,\n",
    "    steps_per_epoch=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and resume training\n",
    "\n",
    "This loads the saved model and passes it the augmentation pipeline and `DataGenerator` from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0929 10:31:25.760160 4656326080 deprecation.py:506] From /Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0929 10:31:25.772601 4656326080 deprecation.py:506] From /Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0929 10:31:25.774595 4656326080 deprecation.py:506] From /Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\n",
    "    HOME + \"/deepposekit-data/datasets/fly/best_model_densenet.h5\",\n",
    "    augmenter=augmenter,\n",
    "    generator=data_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resume training, simply call `model.fit` again. We'll run it for another 30 `epochs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 121.3339 - output_0_loss: 79.7548 - output_1_loss: 41.5791\n",
      "Epoch 00001: val_loss improved from 114.22691 to 104.32965, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  4.12 (0%:  0.04, 5%:  0.54, 25%:  1.35, 50%:  2.17, 75%:  3.65, 95%: 11.59, 100%: 143.08) \n",
      "confidence - mean:  0.58 (0%:  0.05, 5%:  0.30, 25%:  0.48, 50%:  0.60, 75%:  0.70, 95%:  0.81, 100%:  1.02) \n",
      "\n",
      "270/270 [==============================] - 106s 394ms/step - loss: 121.3312 - output_0_loss: 79.7473 - output_1_loss: 41.5839 - val_loss: 104.3296 - val_output_0_loss: 71.4908 - val_output_1_loss: 32.8388\n",
      "Epoch 2/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 114.7393 - output_0_loss: 76.2748 - output_1_loss: 38.4645\n",
      "Epoch 00002: val_loss improved from 104.32965 to 103.56771, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.65 (0%:  0.04, 5%:  0.57, 25%:  1.36, 50%:  2.15, 75%:  3.56, 95%: 10.40, 100%: 131.02) \n",
      "confidence - mean:  0.62 (0%:  0.06, 5%:  0.31, 25%:  0.53, 50%:  0.65, 75%:  0.74, 95%:  0.85, 100%:  1.05) \n",
      "\n",
      "270/270 [==============================] - 96s 356ms/step - loss: 114.7110 - output_0_loss: 76.2529 - output_1_loss: 38.4581 - val_loss: 103.5677 - val_output_0_loss: 70.5360 - val_output_1_loss: 33.0317\n",
      "Epoch 3/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 109.3878 - output_0_loss: 73.3077 - output_1_loss: 36.0801\n",
      "Epoch 00003: val_loss improved from 103.56771 to 98.84510, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.58 (0%:  0.00, 5%:  0.62, 25%:  1.49, 50%:  2.30, 75%:  3.61, 95%:  9.60, 100%: 131.56) \n",
      "confidence - mean:  0.60 (0%:  0.05, 5%:  0.29, 25%:  0.51, 50%:  0.62, 75%:  0.72, 95%:  0.84, 100%:  1.01) \n",
      "\n",
      "270/270 [==============================] - 97s 359ms/step - loss: 109.4084 - output_0_loss: 73.3226 - output_1_loss: 36.0858 - val_loss: 98.8451 - val_output_0_loss: 66.8076 - val_output_1_loss: 32.0375\n",
      "Epoch 4/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 105.6699 - output_0_loss: 71.1297 - output_1_loss: 34.5402\n",
      "Epoch 00004: val_loss improved from 98.84510 to 91.72488, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.18 (0%:  0.00, 5%:  0.49, 25%:  1.20, 50%:  1.95, 75%:  3.18, 95%:  9.21, 100%: 116.32) \n",
      "confidence - mean:  0.66 (0%:  0.09, 5%:  0.35, 25%:  0.55, 50%:  0.69, 75%:  0.78, 95%:  0.89, 100%:  1.09) \n",
      "\n",
      "270/270 [==============================] - 93s 344ms/step - loss: 105.6464 - output_0_loss: 71.1242 - output_1_loss: 34.5222 - val_loss: 91.7249 - val_output_0_loss: 63.3978 - val_output_1_loss: 28.3271\n",
      "Epoch 5/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 101.8896 - output_0_loss: 68.7296 - output_1_loss: 33.1599\n",
      "Epoch 00005: val_loss improved from 91.72488 to 90.23023, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.17 (0%:  0.04, 5%:  0.54, 25%:  1.24, 50%:  1.99, 75%:  3.15, 95%:  8.82, 100%: 111.17) \n",
      "confidence - mean:  0.63 (0%:  0.04, 5%:  0.32, 25%:  0.53, 50%:  0.65, 75%:  0.75, 95%:  0.85, 100%:  1.02) \n",
      "\n",
      "270/270 [==============================] - 94s 347ms/step - loss: 101.8560 - output_0_loss: 68.7088 - output_1_loss: 33.1471 - val_loss: 90.2302 - val_output_0_loss: 61.9606 - val_output_1_loss: 28.2696\n",
      "Epoch 6/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 98.8773 - output_0_loss: 66.7205 - output_1_loss: 32.1568\n",
      "Epoch 00006: val_loss improved from 90.23023 to 87.29301, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.29 (0%:  0.04, 5%:  0.54, 25%:  1.30, 50%:  2.04, 75%:  3.27, 95%:  9.18, 100%: 116.47) \n",
      "confidence - mean:  0.64 (0%:  0.07, 5%:  0.31, 25%:  0.53, 50%:  0.66, 75%:  0.76, 95%:  0.87, 100%:  1.01) \n",
      "\n",
      "270/270 [==============================] - 91s 339ms/step - loss: 98.8621 - output_0_loss: 66.7077 - output_1_loss: 32.1544 - val_loss: 87.2930 - val_output_0_loss: 59.4121 - val_output_1_loss: 27.8809\n",
      "Epoch 7/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 95.2996 - output_0_loss: 64.1218 - output_1_loss: 31.1778\n",
      "Epoch 00007: val_loss improved from 87.29301 to 83.96689, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.96 (0%:  0.04, 5%:  0.51, 25%:  1.20, 50%:  1.90, 75%:  3.02, 95%:  7.79, 100%: 82.75) \n",
      "confidence - mean:  0.66 (0%:  0.06, 5%:  0.36, 25%:  0.58, 50%:  0.68, 75%:  0.78, 95%:  0.88, 100%:  1.09) \n",
      "\n",
      "270/270 [==============================] - 93s 345ms/step - loss: 95.3204 - output_0_loss: 64.1223 - output_1_loss: 31.1981 - val_loss: 83.9669 - val_output_0_loss: 56.1488 - val_output_1_loss: 27.8181\n",
      "Epoch 8/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 93.3003 - output_0_loss: 62.7061 - output_1_loss: 30.5942\n",
      "Epoch 00008: val_loss improved from 83.96689 to 80.04042, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.83 (0%:  0.00, 5%:  0.46, 25%:  1.13, 50%:  1.81, 75%:  2.92, 95%:  7.65, 100%: 84.45) \n",
      "confidence - mean:  0.63 (0%:  0.04, 5%:  0.32, 25%:  0.53, 50%:  0.65, 75%:  0.75, 95%:  0.89, 100%:  1.18) \n",
      "\n",
      "270/270 [==============================] - 94s 347ms/step - loss: 93.3075 - output_0_loss: 62.7090 - output_1_loss: 30.5985 - val_loss: 80.0404 - val_output_0_loss: 54.2792 - val_output_1_loss: 25.7612\n",
      "Epoch 9/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 90.2262 - output_0_loss: 60.4631 - output_1_loss: 29.7631\n",
      "Epoch 00009: val_loss did not improve from 80.04042\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.03 (0%:  0.04, 5%:  0.61, 25%:  1.36, 50%:  2.04, 75%:  3.16, 95%:  7.92, 100%: 66.43) \n",
      "confidence - mean:  0.69 (0%:  0.05, 5%:  0.33, 25%:  0.57, 50%:  0.72, 75%:  0.82, 95%:  0.94, 100%:  1.24) \n",
      "\n",
      "270/270 [==============================] - 95s 350ms/step - loss: 90.2077 - output_0_loss: 60.4527 - output_1_loss: 29.7550 - val_loss: 83.5392 - val_output_0_loss: 56.3484 - val_output_1_loss: 27.1908\n",
      "Epoch 10/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 88.3016 - output_0_loss: 59.1547 - output_1_loss: 29.1469\n",
      "Epoch 00010: val_loss improved from 80.04042 to 76.92370, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.80 (0%:  0.00, 5%:  0.50, 25%:  1.17, 50%:  1.86, 75%:  2.89, 95%:  7.38, 100%: 93.95) \n",
      "confidence - mean:  0.68 (0%:  0.03, 5%:  0.37, 25%:  0.58, 50%:  0.71, 75%:  0.79, 95%:  0.91, 100%:  1.09) \n",
      "\n",
      "270/270 [==============================] - 98s 364ms/step - loss: 88.2957 - output_0_loss: 59.1435 - output_1_loss: 29.1522 - val_loss: 76.9237 - val_output_0_loss: 51.9865 - val_output_1_loss: 24.9372\n",
      "Epoch 11/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 86.4064 - output_0_loss: 57.6770 - output_1_loss: 28.7294\n",
      "Epoch 00011: val_loss improved from 76.92370 to 75.83860, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.87 (0%:  0.04, 5%:  0.50, 25%:  1.19, 50%:  1.88, 75%:  2.93, 95%:  7.84, 100%: 90.44) \n",
      "confidence - mean:  0.67 (0%:  0.04, 5%:  0.38, 25%:  0.59, 50%:  0.69, 75%:  0.78, 95%:  0.91, 100%:  1.09) \n",
      "\n",
      "270/270 [==============================] - 109s 404ms/step - loss: 86.3987 - output_0_loss: 57.6678 - output_1_loss: 28.7310 - val_loss: 75.8386 - val_output_0_loss: 51.4909 - val_output_1_loss: 24.3477\n",
      "Epoch 12/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 84.7232 - output_0_loss: 56.4873 - output_1_loss: 28.2359\n",
      "Epoch 00012: val_loss did not improve from 75.83860\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  3.00 (0%:  0.00, 5%:  0.57, 25%:  1.29, 50%:  1.98, 75%:  3.08, 95%:  8.01, 100%: 84.58) \n",
      "confidence - mean:  0.68 (0%:  0.08, 5%:  0.39, 25%:  0.59, 50%:  0.70, 75%:  0.79, 95%:  0.91, 100%:  1.10) \n",
      "\n",
      "270/270 [==============================] - 106s 392ms/step - loss: 84.8099 - output_0_loss: 56.5372 - output_1_loss: 28.2728 - val_loss: 77.3587 - val_output_0_loss: 52.2996 - val_output_1_loss: 25.0591\n",
      "Epoch 13/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 82.8562 - output_0_loss: 54.9450 - output_1_loss: 27.9112\n",
      "Epoch 00013: val_loss improved from 75.83860 to 73.57035, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.72 (0%:  0.04, 5%:  0.47, 25%:  1.08, 50%:  1.73, 75%:  2.76, 95%:  7.67, 100%: 93.38) \n",
      "confidence - mean:  0.66 (0%:  0.04, 5%:  0.35, 25%:  0.57, 50%:  0.69, 75%:  0.78, 95%:  0.90, 100%:  1.04) \n",
      "\n",
      "270/270 [==============================] - 110s 406ms/step - loss: 82.8141 - output_0_loss: 54.9244 - output_1_loss: 27.8897 - val_loss: 73.5703 - val_output_0_loss: 50.0395 - val_output_1_loss: 23.5308\n",
      "Epoch 14/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 81.9819 - output_0_loss: 54.2365 - output_1_loss: 27.7454\n",
      "Epoch 00014: val_loss improved from 73.57035 to 72.85951, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.69 (0%:  0.04, 5%:  0.50, 25%:  1.12, 50%:  1.76, 75%:  2.76, 95%:  7.14, 100%: 93.48) \n",
      "confidence - mean:  0.67 (0%:  0.03, 5%:  0.36, 25%:  0.57, 50%:  0.69, 75%:  0.79, 95%:  0.88, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 107s 398ms/step - loss: 81.9849 - output_0_loss: 54.2255 - output_1_loss: 27.7594 - val_loss: 72.8595 - val_output_0_loss: 49.2806 - val_output_1_loss: 23.5789\n",
      "Epoch 15/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 79.8273 - output_0_loss: 52.7663 - output_1_loss: 27.0610\n",
      "Epoch 00015: val_loss did not improve from 72.85951\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.84 (0%:  0.00, 5%:  0.49, 25%:  1.16, 50%:  1.82, 75%:  2.97, 95%:  7.83, 100%: 66.34) \n",
      "confidence - mean:  0.70 (0%:  0.05, 5%:  0.42, 25%:  0.61, 50%:  0.72, 75%:  0.81, 95%:  0.92, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 107s 398ms/step - loss: 79.8144 - output_0_loss: 52.7593 - output_1_loss: 27.0551 - val_loss: 73.2164 - val_output_0_loss: 48.5222 - val_output_1_loss: 24.6942\n",
      "Epoch 16/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 77.9953 - output_0_loss: 51.4100 - output_1_loss: 26.5853\n",
      "Epoch 00016: val_loss improved from 72.85951 to 68.68614, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.65 (0%:  0.00, 5%:  0.45, 25%:  1.05, 50%:  1.66, 75%:  2.66, 95%:  6.94, 100%: 93.85) \n",
      "confidence - mean:  0.70 (0%:  0.03, 5%:  0.40, 25%:  0.61, 50%:  0.72, 75%:  0.82, 95%:  0.92, 100%:  1.07) \n",
      "\n",
      "270/270 [==============================] - 105s 390ms/step - loss: 77.9791 - output_0_loss: 51.4050 - output_1_loss: 26.5741 - val_loss: 68.6861 - val_output_0_loss: 46.1730 - val_output_1_loss: 22.5131\n",
      "Epoch 17/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 77.0269 - output_0_loss: 50.5926 - output_1_loss: 26.4342\n",
      "Epoch 00017: val_loss improved from 68.68614 to 68.46759, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.64 (0%:  0.00, 5%:  0.50, 25%:  1.14, 50%:  1.77, 75%:  2.74, 95%:  6.67, 100%: 66.89) \n",
      "confidence - mean:  0.68 (0%:  0.03, 5%:  0.41, 25%:  0.59, 50%:  0.70, 75%:  0.80, 95%:  0.90, 100%:  1.03) \n",
      "\n",
      "270/270 [==============================] - 106s 392ms/step - loss: 77.0625 - output_0_loss: 50.6015 - output_1_loss: 26.4610 - val_loss: 68.4676 - val_output_0_loss: 46.2066 - val_output_1_loss: 22.2610\n",
      "Epoch 18/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 75.0746 - output_0_loss: 49.3482 - output_1_loss: 25.7263\n",
      "Epoch 00018: val_loss improved from 68.46759 to 66.66554, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.63 (0%:  0.00, 5%:  0.49, 25%:  1.12, 50%:  1.76, 75%:  2.68, 95%:  6.90, 100%: 75.52) \n",
      "confidence - mean:  0.68 (0%:  0.06, 5%:  0.41, 25%:  0.60, 50%:  0.70, 75%:  0.79, 95%:  0.90, 100%:  1.05) \n",
      "\n",
      "270/270 [==============================] - 106s 393ms/step - loss: 75.1213 - output_0_loss: 49.3692 - output_1_loss: 25.7521 - val_loss: 66.6655 - val_output_0_loss: 44.8494 - val_output_1_loss: 21.8161\n",
      "Epoch 19/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 74.1545 - output_0_loss: 48.5294 - output_1_loss: 25.6251\n",
      "Epoch 00019: val_loss improved from 66.66554 to 65.67079, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.54 (0%:  0.00, 5%:  0.47, 25%:  1.08, 50%:  1.69, 75%:  2.66, 95%:  6.69, 100%: 70.05) \n",
      "confidence - mean:  0.68 (0%:  0.02, 5%:  0.39, 25%:  0.58, 50%:  0.69, 75%:  0.80, 95%:  0.92, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 103s 382ms/step - loss: 74.1950 - output_0_loss: 48.5479 - output_1_loss: 25.6471 - val_loss: 65.6708 - val_output_0_loss: 44.0967 - val_output_1_loss: 21.5741\n",
      "Epoch 20/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 73.8800 - output_0_loss: 48.2261 - output_1_loss: 25.6539\n",
      "Epoch 00020: val_loss did not improve from 65.67079\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.64 (0%:  0.00, 5%:  0.49, 25%:  1.15, 50%:  1.80, 75%:  2.80, 95%:  6.77, 100%: 67.13) \n",
      "confidence - mean:  0.67 (0%:  0.03, 5%:  0.37, 25%:  0.58, 50%:  0.69, 75%:  0.78, 95%:  0.89, 100%:  1.04) \n",
      "\n",
      "270/270 [==============================] - 98s 362ms/step - loss: 73.8092 - output_0_loss: 48.1856 - output_1_loss: 25.6236 - val_loss: 66.8742 - val_output_0_loss: 44.1371 - val_output_1_loss: 22.7371\n",
      "Epoch 21/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 72.7247 - output_0_loss: 47.4421 - output_1_loss: 25.2826\n",
      "Epoch 00021: val_loss improved from 65.67079 to 65.19596, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.68 (0%:  0.00, 5%:  0.51, 25%:  1.18, 50%:  1.81, 75%:  2.74, 95%:  6.75, 100%: 66.62) \n",
      "confidence - mean:  0.70 (0%:  0.04, 5%:  0.42, 25%:  0.61, 50%:  0.72, 75%:  0.81, 95%:  0.92, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 104s 384ms/step - loss: 72.7021 - output_0_loss: 47.4286 - output_1_loss: 25.2735 - val_loss: 65.1960 - val_output_0_loss: 43.2573 - val_output_1_loss: 21.9387\n",
      "Epoch 22/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 72.0689 - output_0_loss: 46.9591 - output_1_loss: 25.1099\n",
      "Epoch 00022: val_loss did not improve from 65.19596\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.84 (0%:  0.00, 5%:  0.58, 25%:  1.34, 50%:  2.04, 75%:  3.01, 95%:  7.23, 100%: 65.04) \n",
      "confidence - mean:  0.69 (0%:  0.03, 5%:  0.39, 25%:  0.61, 50%:  0.71, 75%:  0.80, 95%:  0.90, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 104s 384ms/step - loss: 72.0844 - output_0_loss: 46.9678 - output_1_loss: 25.1167 - val_loss: 68.0890 - val_output_0_loss: 44.2231 - val_output_1_loss: 23.8659\n",
      "Epoch 23/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 70.7109 - output_0_loss: 46.0735 - output_1_loss: 24.6373\n",
      "Epoch 00023: val_loss improved from 65.19596 to 62.65193, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.49 (0%:  0.04, 5%:  0.46, 25%:  1.08, 50%:  1.68, 75%:  2.53, 95%:  6.39, 100%: 64.21) \n",
      "confidence - mean:  0.68 (0%:  0.02, 5%:  0.39, 25%:  0.60, 50%:  0.70, 75%:  0.79, 95%:  0.89, 100%:  1.09) \n",
      "\n",
      "270/270 [==============================] - 107s 397ms/step - loss: 70.7030 - output_0_loss: 46.0712 - output_1_loss: 24.6318 - val_loss: 62.6519 - val_output_0_loss: 41.6648 - val_output_1_loss: 20.9871\n",
      "Epoch 24/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 70.1915 - output_0_loss: 45.5399 - output_1_loss: 24.6516\n",
      "Epoch 00024: val_loss improved from 62.65193 to 59.95037, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.46 (0%:  0.01, 5%:  0.43, 25%:  1.05, 50%:  1.64, 75%:  2.51, 95%:  6.49, 100%: 66.71) \n",
      "confidence - mean:  0.69 (0%:  0.03, 5%:  0.41, 25%:  0.60, 50%:  0.71, 75%:  0.80, 95%:  0.92, 100%:  1.07) \n",
      "\n",
      "270/270 [==============================] - 109s 405ms/step - loss: 70.1783 - output_0_loss: 45.5349 - output_1_loss: 24.6434 - val_loss: 59.9504 - val_output_0_loss: 40.0507 - val_output_1_loss: 19.8996\n",
      "Epoch 25/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 69.9028 - output_0_loss: 45.3226 - output_1_loss: 24.5803\n",
      "Epoch 00025: val_loss did not improve from 59.95037\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.45 (0%:  0.00, 5%:  0.43, 25%:  1.02, 50%:  1.58, 75%:  2.47, 95%:  6.38, 100%: 92.61) \n",
      "confidence - mean:  0.70 (0%:  0.04, 5%:  0.42, 25%:  0.61, 50%:  0.72, 75%:  0.81, 95%:  0.93, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 107s 398ms/step - loss: 69.8766 - output_0_loss: 45.3138 - output_1_loss: 24.5628 - val_loss: 60.1880 - val_output_0_loss: 40.1136 - val_output_1_loss: 20.0744\n",
      "Epoch 26/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 68.6631 - output_0_loss: 44.4764 - output_1_loss: 24.1867\n",
      "Epoch 00026: val_loss improved from 59.95037 to 59.24072, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.48 (0%:  0.00, 5%:  0.47, 25%:  1.09, 50%:  1.68, 75%:  2.55, 95%:  6.42, 100%: 71.65) \n",
      "confidence - mean:  0.70 (0%:  0.04, 5%:  0.42, 25%:  0.61, 50%:  0.71, 75%:  0.81, 95%:  0.92, 100%:  1.05) \n",
      "\n",
      "270/270 [==============================] - 102s 377ms/step - loss: 68.6722 - output_0_loss: 44.4834 - output_1_loss: 24.1887 - val_loss: 59.2407 - val_output_0_loss: 38.8792 - val_output_1_loss: 20.3615\n",
      "Epoch 27/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 68.3496 - output_0_loss: 44.1385 - output_1_loss: 24.2110\n",
      "Epoch 00027: val_loss did not improve from 59.24072\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.61 (0%:  0.04, 5%:  0.56, 25%:  1.22, 50%:  1.82, 75%:  2.71, 95%:  6.43, 100%: 93.65) \n",
      "confidence - mean:  0.68 (0%:  0.03, 5%:  0.41, 25%:  0.60, 50%:  0.70, 75%:  0.79, 95%:  0.90, 100%:  1.02) \n",
      "\n",
      "270/270 [==============================] - 97s 360ms/step - loss: 68.3302 - output_0_loss: 44.1242 - output_1_loss: 24.2060 - val_loss: 60.5854 - val_output_0_loss: 39.1089 - val_output_1_loss: 21.4766\n",
      "Epoch 28/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 67.0157 - output_0_loss: 43.2211 - output_1_loss: 23.7946\n",
      "Epoch 00028: val_loss improved from 59.24072 to 58.14435, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.39 (0%:  0.03, 5%:  0.43, 25%:  1.02, 50%:  1.61, 75%:  2.45, 95%:  6.24, 100%: 92.85) \n",
      "confidence - mean:  0.70 (0%:  0.06, 5%:  0.42, 25%:  0.62, 50%:  0.72, 75%:  0.82, 95%:  0.92, 100%:  1.11) \n",
      "\n",
      "270/270 [==============================] - 100s 369ms/step - loss: 67.0459 - output_0_loss: 43.2485 - output_1_loss: 23.7974 - val_loss: 58.1444 - val_output_0_loss: 38.6342 - val_output_1_loss: 19.5102\n",
      "Epoch 29/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 66.8682 - output_0_loss: 43.0885 - output_1_loss: 23.7797\n",
      "Epoch 00029: val_loss did not improve from 58.14435\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.63 (0%:  0.00, 5%:  0.51, 25%:  1.18, 50%:  1.81, 75%:  2.73, 95%:  6.50, 100%: 66.95) \n",
      "confidence - mean:  0.71 (0%:  0.04, 5%:  0.44, 25%:  0.62, 50%:  0.72, 75%:  0.81, 95%:  0.95, 100%:  1.08) \n",
      "\n",
      "270/270 [==============================] - 106s 391ms/step - loss: 66.8713 - output_0_loss: 43.0946 - output_1_loss: 23.7767 - val_loss: 58.9094 - val_output_0_loss: 38.2140 - val_output_1_loss: 20.6954\n",
      "Epoch 30/30\n",
      "269/270 [============================>.] - ETA: 0s - loss: 66.4804 - output_0_loss: 42.7867 - output_1_loss: 23.6936\n",
      "Epoch 00030: val_loss improved from 58.14435 to 56.56964, saving model to /Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5\n",
      "evaluation_metrics: \n",
      "euclidean - mean:  2.44 (0%:  0.04, 5%:  0.45, 25%:  1.07, 50%:  1.65, 75%:  2.49, 95%:  6.40, 100%: 66.71) \n",
      "confidence - mean:  0.70 (0%:  0.02, 5%:  0.43, 25%:  0.61, 50%:  0.71, 75%:  0.80, 95%:  0.93, 100%:  1.07) \n",
      "\n",
      "270/270 [==============================] - 100s 371ms/step - loss: 66.4605 - output_0_loss: 42.7720 - output_1_loss: 23.6885 - val_loss: 56.5696 - val_output_0_loss: 37.1893 - val_output_1_loss: 19.3804\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    batch_size=5,\n",
    "    validation_batch_size=10,\n",
    "    callbacks=callbacks,\n",
    "    epochs=30,\n",
    "    n_workers=8,\n",
    "    steps_per_epoch=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
